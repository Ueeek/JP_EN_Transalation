{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-LSTM jp->en",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ueeek/JP_EN_Transalation/blob/master/2_LSTM_jp_%3Een.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWaTzQNB7fA9",
        "colab_type": "text"
      },
      "source": [
        "# 内容"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_py8zoB7kAeG",
        "colab_type": "text"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1FmP1GB7uIX",
        "colab_type": "text"
      },
      "source": [
        "## drive のマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5bAtQyp7eF_",
        "colab_type": "code",
        "outputId": "1c3a872b-9cb6-478a-b97e-055f3443d603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xxkKklip1eD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHqfantn70if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjEeJlCr78vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = \"drive/My Drive/ted_translation/\".replace(\"/\",os.sep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnB9Rtf37_hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_file =base_dir+\"data/jpn.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qihW012i5I-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_dir = base_dir+\"trained_model/2lstm02.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65yiok4aiotL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_col=\"description_jp\"\n",
        "trg_col = \"description_en\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkOOQoL8HHq",
        "colab_type": "text"
      },
      "source": [
        " ## コーパスの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW7IdF3m8F2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "import string \n",
        "import re\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzPWwaAD8vgi",
        "colab_type": "text"
      },
      "source": [
        "# 前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8B4bRPt8xem",
        "colab_type": "text"
      },
      "source": [
        "## word to index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhIPg2xNbmoH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG2FEA6N8-ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token=1\n",
        "EOS_token=0\n",
        "UNK_token=2\n",
        "max_features=5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q3KHxd0U_Wh",
        "colab_type": "code",
        "outputId": "0cb0fcc6-aac3-4d8b-bca9-4509a79b1a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! pip3 install mosestokenizer "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mosestokenizer in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: toolwrapper in /usr/local/lib/python3.6/dist-packages (from mosestokenizer) (0.4.1)\n",
            "Requirement already satisfied: openfile in /usr/local/lib/python3.6/dist-packages (from mosestokenizer) (0.0.7)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from mosestokenizer) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hi541SXVIs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mosestokenizer as mos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgjMgREn8eIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LangEn:\n",
        "    def __init__(self,name):\n",
        "        self.name= name\n",
        "        self.word2index={\"SOS\":SOS_token,\"EOS\":EOS_token,\"UNK\":UNK_token}\n",
        "        self.word2count={}\n",
        "        self.index2word={SOS_token:\"SOS\",EOS_token:\"EOS\",UNK_token:\"UNK\"}\n",
        "        self.n_words = 3\n",
        "        self.tokenizer = mos.MosesTokenizer(\"en\")\n",
        "    def addSentence(self,sentence):\n",
        "        for word in  self.tokenizer(sentence):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self,word):\n",
        "        if word not in self.word2index  :\n",
        "            if self.n_words >= max_features:\n",
        "                return\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word]=1\n",
        "            self.index2word[self.n_words]=word\n",
        "            self.n_words+=1\n",
        "        else:\n",
        "            self.word2count[word]+=1\n",
        "            \n",
        "            \n",
        "    def word2id(self,sentence,target=False):\n",
        "        ret=[]\n",
        "        if target:\n",
        "            ret.append(self.word2index[\"SOS\"])\n",
        "        for word in self.tokenizer(sentence):\n",
        "            try:\n",
        "                word_id = self.word2index[word]\n",
        "            except KeyError:\n",
        "                word_id = self.word2index[\"UNK\"]\n",
        "            ret.append(word_id)\n",
        "        ret.append(EOS_token)\n",
        "        return ret\n",
        "    \n",
        "    \n",
        "    def id2word(self,ids):\n",
        "        ret=[]\n",
        "        for id in ids:\n",
        "            try:\n",
        "                word = self.index2word[id]\n",
        "            except KeyError:\n",
        "                word = \"UNK\"\n",
        "            ret.append(word)\n",
        "        return ret\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_3qeFNF9HoM",
        "colab_type": "code",
        "outputId": "acc63a8c-d03f-416d-f2c5-a244b50d3c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# colab　にmecabを入れる\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.4)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.7)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.2)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.4)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.7)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.2)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3==0.7 in /usr/local/lib/python3.6/dist-packages (0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUfODMum9CN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "class LangJa:\n",
        "    def __init__(self,name):\n",
        "        self.name= name\n",
        "        self.word2index={\"SOS\":SOS_token,\"EOS\":EOS_token,\"UNK\":UNK_token}\n",
        "        self.word2count={}\n",
        "        self.index2word={SOS_token:\"SOS\",EOS_token:\"EOS\",UNK_token:\"UNK\"}\n",
        "        self.n_words = 3\n",
        "        self.tagger = MeCab.Tagger(\"-Owakati\")\n",
        "        \n",
        "    def addSentence(self,sentence):\n",
        "        for word in self.tagger.parse(sentence).split():\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self,word):\n",
        "        if word not in self.word2index:\n",
        "            if self.n_words >= max_features:\n",
        "                return\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word]=1\n",
        "            self.index2word[self.n_words]=word\n",
        "            self.n_words+=1\n",
        "        else:\n",
        "            self.word2count[word]+=1\n",
        "            \n",
        "    def word2id(self,sentence,target=False):\n",
        "        ret=[]\n",
        "        if target:\n",
        "            ret.append(self.word2index[\"SOS\"])\n",
        "        for word in self.tagger.parse(sentence).split():\n",
        "            try:\n",
        "                word_id=self.word2index[word]\n",
        "            except KeyError:\n",
        "                word_id = self.word2index[\"UNK\"]\n",
        "            ret.append(word_id)\n",
        "        ret.append(EOS_token)\n",
        "        return ret\n",
        "        \n",
        "        \n",
        "    def id2word(self,ids):\n",
        "        ret=[]\n",
        "        for id in ids:\n",
        "            try:\n",
        "                word = self.index2word[id]\n",
        "            except KeyError:\n",
        "                word = \"UNK\"\n",
        "            ret.append(word)\n",
        "        return ret\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVSNRhqZ9mDT",
        "colab_type": "text"
      },
      "source": [
        "## normalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVRZTS0j9o5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return \" \".join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!=\"Mn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVOAmo129qcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeString(s):\n",
        "    ret=[]\n",
        "    for c in s.split():\n",
        "        c = unicodeToAscii(c.lower())\n",
        "        c = re.sub(r\"([.!?])\", r\" \\1\", c)\n",
        "        c = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", c)\n",
        "        ret.append(\"\".join(c.split()))\n",
        "    return \" \".join(ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfFinv3R9r1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm_jp(sentence):\n",
        "    tagger = MeCab.Tagger(\"-Owakati\")\n",
        "    ret=[]\n",
        "    for word in tagger.parse(sentence).split():\n",
        "        word = re.sub(r\"([、。])\",r\"\\1\",word)\n",
        "        ret.append(\"\".join(word.split()))\n",
        "    return \" \".join(ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPr4nk6J9tZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadLangs():\n",
        "    print(\"reading lines\")\n",
        "    data = pd.read_csv(corpus_file,sep=\"\\t\",names=[trg_col,src_col])\n",
        "    data = data.sample(frac=1).reset_index(drop=True)\n",
        "    data[src_col] = data[src_col].apply(lambda x:\"\".join(norm_jp(x)))\n",
        "    data[trg_col] = data[trg_col].apply(lambda x:\"\".join(normalizeString(x)))\n",
        "    return data[[src_col,trg_col]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUhTVfkkwx4n",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPlTuEwxVvKC",
        "colab_type": "text"
      },
      "source": [
        "## keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ehnGmunVwYn",
        "colab_type": "code",
        "outputId": "1ccdd02b-5f4d-471e-f247-b81dc3838ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import  Model\n",
        "from keras.layers import Input,Dense,Add,Concatenate,Reshape,Dot,Softmax,Lambda\n",
        "from keras.layers import LSTM,Embedding,Dropout,BatchNormalization\n",
        "from keras.initializers import uniform\n",
        "from keras import backend  as K\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from math import ceil"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXZNqJRrbnfS",
        "colab_type": "text"
      },
      "source": [
        "### model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFjiCn22blbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2seq:\n",
        "    def __init__(self,maxlen_e,maxlen_d,n_hidden,input_dim,emb_dim,output_dim):\n",
        "        self.maxlen_e=maxlen_e\n",
        "        self.maxlen_d=maxlen_d\n",
        "        self.n_hidden=n_hidden\n",
        "        self.input_dim=input_dim\n",
        "        self.emb_dim=emb_dim\n",
        "        self.output_dim=output_dim\n",
        "\n",
        "    def create_model(self,use_enc_emb=False,use_dec_emb=False,encoder_emb_mat=None,decoder_emb_mat=None):\n",
        "        print(\"#3 encoder\")\n",
        "        # encoder\n",
        "        ## input\n",
        "        encoder_input = Input(shape=(self.maxlen_e,),name=\"encoder_input\")\n",
        "        ## embedding\n",
        "        if use_enc_emb:\n",
        "            emb_input = Embedding(output_dim = self.emb_dim,input_dim = self.input_dim,weights=[encoder_emb_mat])(encoder_input)\n",
        "            \n",
        "        else:\n",
        "            emb_input = Embedding(output_dim = self.emb_dim,input_dim = self.input_dim,embeddings_initializer=uniform(seed=SEED))(encoder_input)\n",
        "        \n",
        "        \n",
        "        ## batch_norm\n",
        "        emb_input = BatchNormalization(axis=-1)(emb_input)\n",
        "        \n",
        "        ## LSMT(forwarding)\n",
        "        enc_fw1,state_h_fw1,state_c_fw1 = LSTM(self.n_hidden,\n",
        "                                             name=\"encoder_LSTM_fw1\",\n",
        "                                             return_sequences=True,\n",
        "                                             return_state = True)(emb_input)\n",
        "        enc_LSTM_fw2 = LSTM(self.n_hidden,\n",
        "                            name=\"encoder_LSTM_fw\",\n",
        "                           return_sequences=True,\n",
        "                           return_state=True)\n",
        "        enc_fw2,state_h_fw2,state_c_fw2 = enc_LSTM_fw2(enc_fw1)\n",
        "        ## LSTM(backword)\n",
        "        enc_bw1,state_h_bw1,state_c_bw1 = LSTM(self.n_hidden,\n",
        "                                              name=\"encoder_LSTM_bw1\",\n",
        "                                              return_sequences=True,\n",
        "                                              return_state=True)(emb_input)\n",
        "        enc_bw2,state_h_bw2,state_c_bw2 = LSTM(self.n_hidden,\n",
        "                                              name=\"encoder_LSTM_bw2\",\n",
        "                                              return_sequences=True,\n",
        "                                              return_state=True)(enc_bw1)\n",
        "        \n",
        "\n",
        "         ## encoder_output\n",
        "        encoder_outputs = Add()([enc_fw2,enc_bw2])\n",
        "        state_h_1 = Add()([state_h_fw1,state_h_bw1])\n",
        "        state_c_1 = Add()([state_c_fw1,state_c_bw1])\n",
        "        state_h_2 = Add()([state_h_fw2,state_h_bw2])\n",
        "        state_c_2 = Add()([state_c_fw2,state_c_bw2])\n",
        "        \n",
        "        encoder_states1 = [state_h_1,state_c_1]\n",
        "        encoder_states2 = [state_h_2,state_c_2]\n",
        "        ## encoder_output\n",
        "       \n",
        "        \n",
        "       ## encoder_model\n",
        "        encoder_model = Model(inputs=encoder_input, outputs=[encoder_outputs,state_h_1,state_c_1,state_h_2,state_c_2])\n",
        "        \n",
        "        print(\"#4 decoder\")\n",
        "        # decoder for train\n",
        "        a_states1 = encoder_states1\n",
        "        a_states2 = encoder_states2\n",
        "        \n",
        "        #define layers\n",
        "        decode_LSTM1 = LSTM(self.n_hidden,\n",
        "                             name=\"decode_LSTM1\",\n",
        "                             return_sequences=True,\n",
        "                             return_state=True)\n",
        "        decode_LSTM2 = LSTM(self.n_hidden,\n",
        "                             name=\"decode_LSTM2\",\n",
        "                             return_sequences=True,\n",
        "                             return_state=True)\n",
        "        decoder_Dense=Dense(self.output_dim,\n",
        "                           activation=\"softmax\",\n",
        "                           name=\"decoder_Dense\")\n",
        "        # deocoder\n",
        "        decoder_inputs = Input(shape=(self.maxlen_d,),name=\"decoder_inputs\")\n",
        "        if use_dec_emb:\n",
        "            dec_emb =Embedding(output_dim = self.emb_dim,\n",
        "                              input_dim = self.output_dim,\n",
        "                              weights=[decoder_emb_mat] )(decoder_inputs)\n",
        "        else:\n",
        "            dec_emb =Embedding(output_dim = self.emb_dim,\n",
        "                              input_dim = self.output_dim,\n",
        "                              embeddings_initializer=uniform(seed=SEED))(decoder_inputs)\n",
        "            \n",
        "        decoder_input = BatchNormalization(axis=-1)(dec_emb)\n",
        "        dec_input=decoder_input\n",
        "        decoder_lstm1,state_s_1,state_c_1 = decode_LSTM1(dec_input,initial_state=encoder_states1)\n",
        "        decoder_lstm2,state_s_2,state_c_2 = decode_LSTM2(decoder_lstm1,initial_state=encoder_states2)\n",
        "        \n",
        "    \n",
        "      \n",
        "        decoder_outputs = decoder_Dense(decoder_lstm2)\n",
        "        print(\"#5\")\n",
        "        \n",
        "        model = Model(inputs=[encoder_input,decoder_inputs],outputs=decoder_outputs)\n",
        "        model.compile(loss=\"categorical_crossentropy\",optimizer=\"Adam\",metrics=[\"categorical_accuracy\"])\n",
        "        \n",
        "        print(\"#6\")\n",
        "        #decoder for generate translation\n",
        "        decoder_state_input_h_1 = Input(shape=(self.n_hidden,),name='input_h_1')\n",
        "        decoder_state_input_c_1 = Input(shape=(self.n_hidden,),name='input_c_1')\n",
        "        decoder_state_input_h_2 = Input(shape=(self.n_hidden,),name='input_h_2')\n",
        "        decoder_state_input_c_2 = Input(shape=(self.n_hidden,),name='input_c_2')\n",
        "      \n",
        "      \n",
        "\n",
        "      ##　上のやつをまとめる\n",
        "        decoder_states_inputs_1 = [decoder_state_input_h_1, decoder_state_input_c_1]\n",
        "        decoder_states_inputs_2 = [decoder_state_input_h_2, decoder_state_input_c_2] \n",
        "        decoder_states_inputs=[decoder_state_input_h_1, decoder_state_input_c_1,\n",
        "                               decoder_state_input_h_2, decoder_state_input_c_2]\n",
        "        \n",
        "        \n",
        "        ##LSTM\n",
        "        decoder_lstm_1,state_h_1,state_c_1 = decode_LSTM1(dec_input,initial_state=decoder_states_inputs_1)\n",
        "        decoder_lstm_2,state_h_2,state_c_2 = decode_LSTM2(decoder_lstm_1,initial_state=decoder_states_inputs_2)\n",
        "        \n",
        "        decoder_states = [state_h_1,state_c_1,state_h_2,state_c_2]\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        print(\"#7\")\n",
        "        #output\n",
        "        decoder_outputs=decoder_Dense(decoder_lstm_2)\n",
        "        \n",
        "        #decoder model\n",
        "        decoder_model=Model(\n",
        "            [decoder_inputs]+decoder_states_inputs,\n",
        "            [decoder_outputs]+decoder_states)\n",
        "        \n",
        "        return model,encoder_model ,decoder_model\n",
        "    \n",
        "    \n",
        "    ## train\n",
        "    def train(self,e_input,d_input,target,emb_dir,batch_size=1,epochs=1,validation_split=0):\n",
        "        print(\"#1 train procedure start\")\n",
        "        model,_,_ = self.create_model(use_enc_emb=True,use_dec_emb=True,encoder_emb_mat=en_embedding_matrix,decoder_emb_mat=jp_embedding_matrix)\n",
        "        model.summary()\n",
        "        \n",
        "        if os.path.isfile(emb_dir): #モデルの学習済みパラメータ\n",
        "            print(\"2-1? load param\")\n",
        "            model.load_weights(emb_dir)\n",
        "        else:\n",
        "            print(\"no_emb\")\n",
        "        print(\"#6 start training\")\n",
        "        \n",
        "        target_categorical = np_utils.to_categorical(output_target_padded,self.output_dim)\n",
        "        \n",
        "       \n",
        "        model.fit([e_input,d_input],target_categorical,epochs=epochs,batch_size=batch_size,validation_split=validation_split)\n",
        "            \n",
        "        print(\"#9 save_param\")\n",
        "        model.save_weights(emb_dir)\n",
        "        return model    \n",
        "        \n",
        "       \n",
        "          \n",
        "\n",
        "    ## 翻訳文生成\n",
        "    def translate(self,e_input,length,encoder_model,decoder_model):\n",
        "        #encode input to vec\n",
        "        encoder_outputs,state_h_1,state_c_1,state_h_2,state_c_2 = encoder_model.predict(e_input)\n",
        "        states_values=[state_h_1,state_c_1,state_h_2,state_c_2]\n",
        "        \n",
        "        \n",
        "        #first token\n",
        "        target_seq=np.zeros((1,1))\n",
        "        target_seq[0,0] = SOS_token #id of SOS (start of sentence)\n",
        "        \n",
        "        decoded_sentence=[]\n",
        "        for i in range(0,length):\n",
        "            output_tokens,h1,c1,h2,c2 = decoder_model.predict([target_seq]+states_values)\n",
        "            \n",
        "            sampled_token_index=np.argmax(output_tokens[0,0,:])\n",
        "            #print(\"token->\",sampled_token_index)\n",
        "            if sampled_token_index==EOS_token: #EOS\n",
        "                decoded_sentence.append(EOS_token)\n",
        "                break\n",
        "            else:\n",
        "                target_seq[0,0] = sampled_token_index\n",
        "                states_values =[h1,c1,h2,c2]\n",
        "                decoded_sentence.append(sampled_token_index)\n",
        "        return decoded_sentence                                    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def translate_demo(self,src_data_id_seq,param_dir):\n",
        "        #model,encoder_model,decoder_model = self.create_model(use_enc_emb=True,use_dec_emb=True,encoder_emb_mat=en_embedding_matrix,decoder_emb_mat=jp_embedding_matrix)\n",
        "        model,encoder_model,decoder_model = self.create_model()\n",
        "        model.load_weights(param_dir)\n",
        "       \n",
        "        ret=[]\n",
        "        for src in src_data_id_seq:\n",
        "            id_seq_mat = np.array([src])\n",
        "            pred_id_padded = sequence.pad_sequences(id_seq_mat,maxlen=MAX_LENGTH,padding=\"post\",truncating=\"post\")\n",
        "            pred=Generate_model.translate(pred_id_padded,20,encoder_model,decoder_model)\n",
        "            ret.append(pred)\n",
        "        return ret\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi2VcZziowa6",
        "colab_type": "text"
      },
      "source": [
        "### model visualizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPWpVFhbblQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from IPython.display import SVG\n",
        "#from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WhbkORYo7gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SVG(model_to_dot(training_model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbcgRAqgo0wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SVG(model_to_dot(encoder_model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvQVZRjbFP4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SVG(model_to_dot(decoder_model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h6V9OfqpcQn",
        "colab_type": "text"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmVIGLgYpdn2",
        "colab_type": "code",
        "outputId": "4926cab7-162c-48d0-829d-e817bf6df815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data=loadLangs()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfRwvehbfHRQ",
        "colab_type": "code",
        "outputId": "08fccc90-205f-4fb2-b194-a2197b47e79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "data[src_col].apply(lambda x:len(x.split())).describe()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    43953.000000\n",
              "mean         9.875867\n",
              "std          4.008849\n",
              "min          1.000000\n",
              "25%          7.000000\n",
              "50%          9.000000\n",
              "75%         12.000000\n",
              "max         58.000000\n",
              "Name: description_jp, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tcOVdwD-Ay9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH= 20\n",
        "def filterPair(data):\n",
        "    return data[data.apply(lambda x:len(x[trg_col].split(\" \")),axis=1)<MAX_LENGTH]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FCy7THnpdim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = filterPair(data)\n",
        "val_data = data[10000:10100]\n",
        "data = data[:15000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsa0heCPpow7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "JP_lang = LangEn(src_col)\n",
        "EN_lang = LangJa(trg_col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWurNSGQpoug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for s in data[trg_col]:\n",
        "    EN_lang.addSentence(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJgN_yKjposQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for s in data[src_col]:\n",
        "    JP_lang.addSentence(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EhW_JCxN4aa",
        "colab_type": "text"
      },
      "source": [
        "## create emb mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXQnzzGyRFGg",
        "colab_type": "text"
      },
      "source": [
        "### load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-20fBCsN7U_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_W2V_FILE = \"./drive/My Drive/util_data/GoogleNews-vectors-negative300.bin.gz\"\n",
        "jp_W2V_FILE=\"./drive/My Drive/util_data/ja_data/ja.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Ql9PJzN7ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_dim=300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sB6vO6iOplW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA-6hirSN7c3",
        "colab_type": "code",
        "outputId": "6bdf0034-905b-4062-f372-b1f2e7c22f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "en_word2vec= KeyedVectors.load_word2vec_format(en_W2V_FILE,binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrN2dsfmOJcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jp_word2vec= model = Word2Vec.load(jp_W2V_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPeBg02HRHAi",
        "colab_type": "text"
      },
      "source": [
        "### create"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGhFF0srOJjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_EMBEDDING_DIM=emb_dim\n",
        "vocabulary_size=min(EN_lang.n_words,max_features)\n",
        "en_embedding_matrix = np.zeros((vocabulary_size, en_EMBEDDING_DIM))\n",
        "print(\"voc->\",vocabulary_size)\n",
        "cnt=0\n",
        "for word, i in EN_lang.word2index.items():\n",
        "    if   i==0 or i==1 or i ==2:\n",
        "        continue\n",
        "    try:\n",
        "        en_embedding_vector = en_word2vec[word]\n",
        "        en_embedding_matrix[i] = en_embedding_vector\n",
        "    except KeyError:\n",
        "        cnt+=1\n",
        "        en_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),en_EMBEDDING_DIM)\n",
        "print(\"UNK_rate\",cnt/i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1scE2JUOJoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jp_EMBEDDING_DIM=emb_dim\n",
        "vocabulary_size=min(JP_lang.n_words,max_features)\n",
        "jp_embedding_matrix = np.zeros((vocabulary_size, jp_EMBEDDING_DIM))\n",
        "print(\"voc->\",vocabulary_size)\n",
        "cnt=0\n",
        "for word, i in JP_lang.word2index.items():\n",
        "    if   i==0 or i==1 or i ==2:\n",
        "        continue\n",
        "    try:\n",
        "        jp_embedding_vector = jp_word2vec[word]\n",
        "        jp_embedding_matrix[i] = jp_embedding_vector\n",
        "    except KeyError:\n",
        "        cnt+=1\n",
        "        jp_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),jp_EMBEDDING_DIM)\n",
        "print(\"UNK/rate->\",cnt/i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCQ7i8BcYA5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RAMの節約\n",
        "del jp_word2vec\n",
        "del en_word2vec\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Tz-dt4YJUu",
        "colab_type": "text"
      },
      "source": [
        "## input の加工"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u6IBzGaKvpYS",
        "colab": {}
      },
      "source": [
        "input_source_lang=data[src_col].apply(lambda x:JP_lang.word2id(x))\n",
        "input_target_lang=data[trg_col].apply(lambda x:EN_lang.word2id(x,target=True))\n",
        "output_target_lang=data[trg_col].apply(lambda x:EN_lang.word2id(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeIt3nCfgitu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[src_col][:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yFmzyN4v_a4",
        "colab_type": "text"
      },
      "source": [
        "Paddning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grwxtrgNwBCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNv2-2QGwJOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=MAX_LENGTH,padding=\"post\",truncating=\"post\")\n",
        "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=MAX_LENGTH,padding=\"post\",truncating=\"post\")\n",
        "output_target_padded=sequence.pad_sequences(output_target_lang,maxlen=MAX_LENGTH,padding=\"post\",truncating=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvDHsUbpqR5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs=5\n",
        "input_dim = EN_lang.n_words\n",
        "output_dim = JP_lang.n_words\n",
        "n_hidden=int(emb_dim+100)\n",
        "SEED=200000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVT_ivvcps4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_model= Seq2seq(maxlen_e=MAX_LENGTH,\n",
        "                              maxlen_d=MAX_LENGTH,\n",
        "                              n_hidden=n_hidden,\n",
        "                              input_dim=input_dim,\n",
        "                              emb_dim = emb_dim,\n",
        "                              output_dim=output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWu7ma4jE8yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " training_model.train(e_input=input_source_padded,\n",
        "                      d_input=input_target_padded,\n",
        "                      target = output_target_padded,\n",
        "                      emb_dir=emb_dir,\n",
        "                      epochs=epochs,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M4yq2eVRox2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8_2NQDMYRrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del training_model\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5khAA1aymGoX",
        "colab_type": "text"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kswIurUqu87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N9v_wwtqu6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_id = val_data[src_col].apply(lambda x:JP_lang.word2id(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA--RWDUHjPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_id[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN89MpyPqu_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generate_model= Seq2seq(maxlen_e=MAX_LENGTH,\n",
        "                              maxlen_d=1,\n",
        "                              n_hidden=n_hidden,\n",
        "                              input_dim=input_dim,\n",
        "                             emb_dim = emb_dim,\n",
        "                              output_dim=output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtzWwyBBCRIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ret=Generate_model.translate_demo(val_data_id,param_dir=emb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0w7srpDEx_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for src,pred,target in zip(val_data[src_col],ret,val_data[trg_col]):\n",
        "    print(\"src->\",src)\n",
        "    print(\"pred->\",EN_lang.id2word(pred))\n",
        "    print(\"ans->\",target)\n",
        "    print(\"------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drEeGLeON8Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}