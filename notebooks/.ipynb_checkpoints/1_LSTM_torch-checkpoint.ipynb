{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "sys.path.append(\"/Users/ueki/Desktop/work/jp_en_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Seq2Seq_1_torch import EncoderRnn,DecoderRnn\n",
    "from utils.LangEn import LangEn\n",
    "from utils.LangJa import LangJa\n",
    "from utils.preprocess import loadLangs\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"corpus_file\":\"../data/jpn.txt\",\n",
    "    \"en_col\":\"description_en\",\n",
    "    \"jp_col\":\"description_jp\",\n",
    "    \"SOS_token\":1,\n",
    "    \"EOS_token\":0,\n",
    "    \"UNK_token\":2,\n",
    "    \"max_features\":5000,\n",
    "    \"MAX_LENGTH\":20,\n",
    "    \"train_size\":15000,\n",
    "    \"val_size\":100,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":20,\n",
    "    \"maxlen_enc\":20,\n",
    "    \"maxlen_dec\":20,\n",
    "    \"n_hidden\":300,\n",
    "    \"input_dim\":5000,\n",
    "    \"output_dim\":5000,\n",
    "    \"emb_dim\":300,\n",
    "    \"use_enc_emb\":False,\n",
    "    \"use_dec_emb\":False,\n",
    "    \"validation_split\":0.1,\n",
    "    \"trained_param_dir\":\"../trained_models/1_lstm_ja_en_01.hdf5\",\n",
    "    \"translate_length\":25,\n",
    "    \"en_W2V_FILE\" : \"../data/GoogleNews-vectors-negative300.bin.gz\",\n",
    "    \"jp_W2V_FILE\":\"../data/ja_data/ja.bin\",\n",
    "    \"src\":\"en\",\n",
    "    \"trg\":\"jp\",\n",
    "    \"learning_rate\":0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class EncoderRnn(nn.Module):\n",
    "    \"\"\"\n",
    "    encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(EncoderRnn, self).__init__()\n",
    "        self.hidden_size = config[\"n_hidden\"]\n",
    "        self.input_size = config[\"max_features\"]\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.lstm = nn.GRU(\n",
    "            self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class DecoderRnn(nn.Module):\n",
    "    \"\"\"\n",
    "    decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(DecoderRnn, self).__init__()\n",
    "        self.hidden_size = config[\"n_hidden\"]\n",
    "        self.output_size = config[\"max_features\"]\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.lstm = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFjiCn22blbf"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,config):\n",
    "        self.print_every=10\n",
    "        self.plot_every=100\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.encoder = EncoderRnn(config)\n",
    "        self.decoder = DecoderRnn(config)\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self. encoder_optimizer = optim.SGD(self.encoder.parameters(),lr = self.learning_rate)\n",
    "        self.decoder_opimizer = optim.SGD(self.decoder.parameters(),lr=self.learning_rate)\n",
    "        \n",
    "    def train(self,input_tensor,target_tensor):\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        \n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_opimizer.zero_grad()\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "        \n",
    "        #encoder\n",
    "        encoder_outputs = torch.zeros(config[\"MAX_LENGTH\"],config[\"n_hidden\"],device=device)\n",
    "        loss = 0\n",
    "        for ei in range(input_length):\n",
    "            encoder_output,encoder_hidden = self.encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0,0]\n",
    "            \n",
    "        # decoder\n",
    "        decoder_input = torch.tensor([[config[\"SOS_token\"]]],device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        for di in range(target_length):\n",
    "            decoder_output,decoder_hidden = self.decoder(decoder_input,decoder_hidden)\n",
    "            loss += self.criterion(decoder_output,target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "        \n",
    "        # back propagate\n",
    "        loss.backward()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_opimizer.step()\n",
    "        return loss.item() / target_length\n",
    "    \n",
    "    def trainIters(self,src,trg,n_iters):\n",
    "        plot_losses=[]\n",
    "        print_loss_total=0\n",
    "        plot_loss_total=0\n",
    "        \n",
    "        encoder_optimizer = optim.SGD(self.encoder.parameters(),lr = self.learning_rate)\n",
    "        decoder_opimizer = optim.SGD(self.decoder.parameters(),lr=self.learning_rate)\n",
    "        \n",
    "        for iter in range(1,n_iters+1):\n",
    "            input_tensor=src[iter-1]\n",
    "            target_tensor=trg[iter-1]\n",
    "            loss =self.train(input_tensor,target_tensor)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "            if iter %self.print_every==0:\n",
    "                print_loss_avg = print_loss_total/self.print_every\n",
    "                print_loss_total=0\n",
    "                print(\"loss_av->\",print_loss_avg)\n",
    "            \n",
    "            if iter % self.plot_every==0:\n",
    "                plot_loss_avg = plot_loss_total/self.plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "        showPlot(plot_losses)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self,config):\n",
    "        self.translate_length = config[\"translate_length\"]\n",
    "        self.trained_param_dir = config[\"trained_param_dir\"]\n",
    "        self.model,self.encoder,self.decoder = build_model(config,test=True)\n",
    "        self.model.load_weights(self.trained_param_dir)\n",
    "    ## 翻訳文生成\n",
    "    def _translate(self,e_input):\n",
    "        #encode input to vec\n",
    "        #encoder_outputs,state_h_1,state_c_1 = self.encoder.predict(e_input)\n",
    "        #states_values=[state_h_1,state_c_1]\n",
    "        encoder_outputs,*states_values = self.encoder.predict(e_input)\n",
    "        \n",
    "        #first token\n",
    "        target_seq=np.zeros((1,1))\n",
    "        target_seq[0,0] = config[\"SOS_token\"]\n",
    "        \n",
    "        decoded_sentence=[]\n",
    "        for i in range(0,self.translate_length):\n",
    "            #output_tokens,h1,c1 = self.decoder.predict([target_seq]+states_values)\n",
    "            output_tokens,*states_values = self.decoder.predict([target_seq]+states_values)\n",
    "            \n",
    "            sampled_token_index=np.argmax(output_tokens[0,0,:])\n",
    "            if sampled_token_index==config[\"EOS_token\"]:\n",
    "                decoded_sentence.append(config[\"EOS_token\"])\n",
    "                break\n",
    "            else:\n",
    "                target_seq[0,0] = sampled_token_index\n",
    "                #states_values =[h1,c1]\n",
    "                decoded_sentence.append(sampled_token_index)\n",
    "        return decoded_sentence                                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def translate_demo(self,src_data_id_seq):\n",
    "        ret=[]\n",
    "        for src in src_data_id_seq:\n",
    "            id_seq_mat = np.array([src])\n",
    "            pred_id_padded = sequence.pad_sequences(id_seq_mat,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "            pred=self._translate(pred_id_padded)\n",
    "            ret.append(pred)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_en_emb(config):\n",
    "    en_word2vec= KeyedVectors.load_word2vec_format(config[\"en_W2V_FILE\"],binary=True)\n",
    "    en_EMBEDDING_DIM=config[\"emb_dim\"]\n",
    "    #n_word<max_featureの時にerrになるよ\n",
    "    vocabulary_size=min(EN_lang.n_words,config[\"max_features\"])\n",
    "    en_embedding_matrix = np.zeros((vocabulary_size, en_EMBEDDING_DIM))\n",
    "    print(\"voc->\",vocabulary_size)\n",
    "    cnt=0\n",
    "    for word, i in EN_lang.word2index.items():\n",
    "        if   i==0 or i==1 or i ==2:\n",
    "            continue\n",
    "        try:\n",
    "            en_embedding_vector = en_word2vec[word]\n",
    "            en_embedding_matrix[i] = en_embedding_vector\n",
    "        except KeyError:\n",
    "            cnt+=1\n",
    "            en_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),en_EMBEDDING_DIM)\n",
    "    print(\"UNK_rate\",cnt/i)\n",
    "    del en_word2vec\n",
    "    gc.collect()\n",
    "    return en_embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "QA-6hirSN7c3",
    "outputId": "e9b07f89-37e4-4be1-e085-9e7cc53a4a20"
   },
   "outputs": [],
   "source": [
    "def build_jp_emb(config):\n",
    "    jp_word2vec= model = Word2Vec.load(config[\"jp_W2V_FILE\"])\n",
    "    jp_EMBEDDING_DIM=config[\"emb_dim\"]\n",
    "    vocabulary_size=min(JP_lang.n_words,config[\"max_features\"])\n",
    "    jp_embedding_matrix = np.zeros((vocabulary_size, jp_EMBEDDING_DIM))\n",
    "    print(\"voc->\",vocabulary_size)\n",
    "    cnt=0\n",
    "    for word, i in JP_lang.word2index.items():\n",
    "        if   i==0 or i==1 or i ==2:\n",
    "            continue\n",
    "        try:\n",
    "            jp_embedding_vector = jp_word2vec[word]\n",
    "            jp_embedding_matrix[i] = jp_embedding_vector\n",
    "        except KeyError:\n",
    "            cnt+=1\n",
    "            jp_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),jp_EMBEDDING_DIM)\n",
    "    print(\"UNK/rate->\",cnt/i)\n",
    "\n",
    "    del jp_word2vec\n",
    "    gc.collect()\n",
    "    return jp_embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h6V9OfqpcQn"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YmVIGLgYpdn2",
    "outputId": "703c3b2f-347a-4377-af52-f1ce4717b447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lines\n"
     ]
    }
   ],
   "source": [
    "data=loadLangs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FCy7THnpdim"
   },
   "outputs": [],
   "source": [
    "val_data = data[config[\"train_size\"]:config[\"train_size\"]+config[\"val_size\"]]\n",
    "data = data[:config[\"train_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsa0heCPpow7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 16:58:22.039391 4477343168 toolwrapper.py:77] stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    }
   ],
   "source": [
    "EN_lang = LangEn(config)\n",
    "JP_lang = LangJa(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWurNSGQpoug"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"en_col\"]]:\n",
    "    EN_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJgN_yKjposQ"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"jp_col\"]]:\n",
    "    JP_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5Tz-dt4YJUu"
   },
   "source": [
    "## input の加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"src\"]==\"jp\":\n",
    "    src_col=config[\"jp_col\"]\n",
    "    trg_col=config[\"en_col\"]\n",
    "    Langs={\"src\":JP_lang,\"trg\":EN_lang}\n",
    "else:\n",
    "    src_col=config[\"en_col\"]\n",
    "    trg_col=config[\"jp_col\"]\n",
    "    Langs={\"trg\":JP_lang,\"src\":EN_lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZkMItuoprY2"
   },
   "outputs": [],
   "source": [
    "input_en = data[src_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6IBzGaKvpYS"
   },
   "outputs": [],
   "source": [
    "input_source_lang=data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
    "input_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x,target=True))\n",
    "output_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNv2-2QGwJOP"
   },
   "outputs": [],
   "source": [
    "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "output_target_padded=sequence.pad_sequences(output_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_src = [torch.tensor(v,dtype=torch.long,device=device).view(-1,1) for v in input_source_padded]\n",
    "input_target = [torch.tensor(v,dtype=torch.long,device=device).view(-1,1) for v in input_target_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_av-> 2.421804723739624\n",
      "loss_av-> 2.791413106918335\n",
      "loss_av-> 2.2305434703826905\n",
      "loss_av-> 2.7967579841613768\n",
      "loss_av-> 2.8629020786285397\n",
      "loss_av-> 2.364283113479614\n",
      "loss_av-> 2.6096621513366696\n",
      "loss_av-> 2.9148748254776\n",
      "loss_av-> 2.288255138397217\n",
      "loss_av-> 2.5413085746765134\n",
      "[2.5821805167198177]\n",
      "loss_av-> 2.5939524745941163\n",
      "loss_av-> 3.1371907711029055\n",
      "loss_av-> 2.570966806411743\n",
      "loss_av-> 3.370115375518799\n",
      "loss_av-> 2.735809564590454\n",
      "loss_av-> 2.6128394412994385\n",
      "loss_av-> 2.558407897949219\n",
      "loss_av-> 2.587490520477295\n",
      "loss_av-> 2.740481948852539\n",
      "loss_av-> 2.0894550275802612\n",
      "[2.5821805167198177, 2.6996709828376777]\n",
      "loss_av-> 2.990668735504151\n",
      "loss_av-> 3.079035491943359\n",
      "loss_av-> 2.703012800216675\n",
      "loss_av-> 2.7002084541320803\n",
      "loss_av-> 2.747833375930786\n",
      "loss_av-> 2.520367460250854\n",
      "loss_av-> 2.3026578044891357\n",
      "loss_av-> 2.8490515136718755\n",
      "loss_av-> 3.3743752574920656\n",
      "loss_av-> 2.6229580688476566\n",
      "[2.5821805167198177, 2.6996709828376777, 2.789016896247865]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.trainIters(input_src,input_target,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m8_2NQDMYRrV",
    "outputId": "577b1ea5-a7c7-4601-983f-e29ad73d26ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del trainer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5khAA1aymGoX"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N9v_wwtqu6E"
   },
   "outputs": [],
   "source": [
    "val_data_id = val_data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aA--RWDUHjPB",
    "outputId": "ac683833-7751-43e7-fd89-01a41abff1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15043                        [206, 20, 560, 8, 1643, 5, 0]\n",
       "15044                    [25, 52, 8, 205, 358, 4270, 5, 0]\n",
       "15045        [10, 512, 351, 215, 3569, 32, 27, 2130, 5, 0]\n",
       "15046                       [18, 56, 1740, 397, 765, 5, 0]\n",
       "15047    [111, 44, 753, 65, 1793, 50, 455, 79, 2360, 5, 0]\n",
       "15048                    [175, 1875, 27, 2983, 2363, 5, 0]\n",
       "15049                    [170, 75, 44, 2, 614, 1219, 5, 0]\n",
       "15050             [490, 22, 44, 2, 2, 12, 144, 1109, 5, 0]\n",
       "15051                           [4, 56, 2, 111, 121, 5, 0]\n",
       "15052        [63, 792, 7, 584, 256, 16, 44, 591, 37, 5, 0]\n",
       "Name: description_en, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-7b2993995cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-61e5f3e4c3e7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"translate_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_param_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trained_param_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_param_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m## 翻訳文生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "translator = Translator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = translator.translate_demo(val_data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0w7srpDEx_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src-> theres no need to hurry.\n",
      "\n",
      "pred-> 急が ない と 遅れる よ 。 EOS\n",
      "ans-> 急ぐ 必要 は あり ませ ん 。\n",
      "------------------\n",
      "src-> i want to join your band.\n",
      "\n",
      "pred-> UNK の 方 が UNK さ れ てる よ 。 EOS\n",
      "ans-> あなた の バンド に 入り たい な 。\n",
      "------------------\n",
      "src-> you must keep an eye on the child.\n",
      "\n",
      "pred-> その 本 は UNK に なり たい 。 EOS\n",
      "ans-> その 子 から 目 を 離さ ない よう に し なけれ ば いけ ない 。\n",
      "------------------\n",
      "src-> he is mad about music.\n",
      "\n",
      "pred-> 彼 は 音楽 が 好き で ある 。 EOS\n",
      "ans-> 彼 は 音楽 狂 だ 。\n",
      "------------------\n",
      "src-> with a little more patience she would have succeeded.\n",
      "\n",
      "pred-> 彼女 が そんな こと を し た ので 、 私 は 何 か 知っ て い まし た 。 EOS\n",
      "ans-> もし 彼女 が もう少し 我慢強かっ たら 、 成功 し て い た だろ う に 。\n",
      "------------------\n",
      "src-> they painted the fence green.\n",
      "\n",
      "pred-> 彼ら は UNK で UNK し て いる 。 EOS\n",
      "ans-> 彼ら は フェンス を 緑色 に 塗っ た 。\n",
      "------------------\n",
      "src-> there was a convention last month.\n",
      "\n",
      "pred-> UNK が UNK た 。 EOS\n",
      "ans-> 先月 、 集会 が あっ た 。\n",
      "------------------\n",
      "src-> shes not a fulltime employee of this company.\n",
      "\n",
      "pred-> 彼女 は UNK UNK も 全く 速く UNK 。 EOS\n",
      "ans-> 彼女 は この 会社 の 正社員 で は あり ませ ん 。\n",
      "------------------\n",
      "src-> tom is arguing with mary.\n",
      "\n",
      "pred-> トム は メアリー と UNK し て いる 。 EOS\n",
      "ans-> トム は メアリー と 喧嘩 し て いる 。\n",
      "------------------\n",
      "src-> it looks like today will be a long day.\n",
      "\n",
      "pred-> 雨 が 降っ て いる ので 、 私 は 犬 に 慣れ ます 。 EOS\n",
      "ans-> 今日 は 長い 一 日 に なり そう です 。\n",
      "------------------\n",
      "src-> tom cried all night long.\n",
      "\n",
      "pred-> トム は 一 日 中 泣い て いる 。 EOS\n",
      "ans-> トム は 一 晩 中 泣き明かし た 。\n",
      "------------------\n",
      "src-> tom didnt want it.\n",
      "\n",
      "pred-> トム は それ を する こと が でき ない 。 EOS\n",
      "ans-> トム は 欲しく なかっ た 。\n",
      "------------------\n",
      "src-> i was moved to tears by her speech.\n",
      "\n",
      "pred-> 私 は 彼女 に 会っ た とたん 、 UNK た 。 EOS\n",
      "ans-> 彼女 の スピーチ で 感動 し て 泣い た 。\n",
      "------------------\n",
      "src-> his wife was nowhere to be seen.\n",
      "\n",
      "pred-> 彼 の 部屋 は きちんと UNK て も 、 UNK し た 。 EOS\n",
      "ans-> 彼 の 妻 の 姿 は どこ に も 見え なかっ た 。\n",
      "------------------\n",
      "src-> in october i was in boston.\n",
      "\n",
      "pred-> その 歌 は よく 知っ て いる 。 EOS\n",
      "ans-> 10 月 は ボストン に い た 。\n",
      "------------------\n",
      "src-> i go to any party i am invited to.\n",
      "\n",
      "pred-> 私 が ここ に 来 て から 、 私 は 普通 は 外出 でき ない 。 EOS\n",
      "ans-> 私 は 招待 さ れ た パーティー に は 必ず 出席 する 。\n",
      "------------------\n",
      "src-> which player are you paying the most attention to this year?\n",
      "\n",
      "pred-> 今日 の 午後 は どう やっ て いく の は ？ EOS\n",
      "ans-> 今年 、 注目 し て いる 選手 は 誰 です か 。\n",
      "------------------\n",
      "src-> he earns more money than he can spend.\n",
      "\n",
      "pred-> 彼 は その 知らせ に 驚い た よう な 。 EOS\n",
      "ans-> 彼 は 使い きれ ない ほど の 金 を 稼ぐ 。\n",
      "------------------\n",
      "src-> i intend to try doing everything i can.\n",
      "\n",
      "pred-> 私 たち は 、 あなた が UNK と 思っ て い ます 。 EOS\n",
      "ans-> できる 限り の こと は し て みる つもり だ 。\n",
      "------------------\n",
      "src-> i dont want to tell you the truth.\n",
      "\n",
      "pred-> そんな こと を し て いる と 言う こと に は ない 。 EOS\n",
      "ans-> あなた に は 本当 の こと を 言い たく ない の 。\n",
      "------------------\n",
      "src-> will it hurt a lot?\n",
      "\n",
      "pred-> ひどく 痛い の ？ EOS\n",
      "ans-> かなり 痛む の です か 。\n",
      "------------------\n",
      "src-> i couldnt answer any questions on the test.\n",
      "\n",
      "pred-> もう 二 人 とも 正しい と 思う ん です 。 EOS\n",
      "ans-> テスト で 一 問 も 答え られ なかっ た 。\n",
      "------------------\n",
      "src-> tom talks like an old man.\n",
      "\n",
      "pred-> トム は 携帯 UNK の が 好き だ 。 EOS\n",
      "ans-> トム は 老人 の よう な 話し方 を する 。\n",
      "------------------\n",
      "src-> he likes to read books.\n",
      "\n",
      "pred-> 彼 は 本 を 読む の が 大好き だ 。 EOS\n",
      "ans-> 彼 は 本 を 読む の が 好き だ 。\n",
      "------------------\n",
      "src-> did you mistake the margarine for butter?\n",
      "\n",
      "pred-> あなた は １ ９ ８ ０ 年 の 主要 な 出来事 と 話し て い ます か 。 EOS\n",
      "ans-> マーガリン を バター と 間違え た の ？\n",
      "------------------\n",
      "src-> i thought nothing of it.\n",
      "\n",
      "pred-> それ は 本当 な こと を 聞い た 。 EOS\n",
      "ans-> なんて こと なかっ た 。\n",
      "------------------\n",
      "src-> parallel lines do not intersect each other.\n",
      "\n",
      "pred-> UNK は UNK と UNK する もの が ある 。 EOS\n",
      "ans-> 平行 線 は 交差 し ませ ん 。\n",
      "------------------\n",
      "src-> im actually a university teacher.\n",
      "\n",
      "pred-> 私 は 先生 に 怒ら れ た 。 EOS\n",
      "ans-> 正確 に 言う と 私 は 大学 講師 です 。\n",
      "------------------\n",
      "src-> ten years have passed since he died.\n",
      "\n",
      "pred-> 彼 が UNK に 入っ た 。 EOS\n",
      "ans-> 彼 が 死ん で から 十 年 に なり ます 。\n",
      "------------------\n",
      "src-> money does not always bring happiness.\n",
      "\n",
      "pred-> 多く の 人 が UNK を し て い ない ん です 。 EOS\n",
      "ans-> お金 が 幸福 を もたらす と は 限ら ない 。\n",
      "------------------\n",
      "src-> she was surprised at the news.\n",
      "\n",
      "pred-> 彼女 は その 知らせ に 驚い た 。 EOS\n",
      "ans-> 彼女 は その ニュース を 聞い て 驚い た 。\n",
      "------------------\n",
      "src-> he stabbed me in the back!\n",
      "\n",
      "pred-> 彼 は 私 に １ 時 に 帰っ て き た 。 EOS\n",
      "ans-> やつ は 僕 を 裏切っ た ん だ ！\n",
      "------------------\n",
      "src-> toms planning something special for marys birthday.\n",
      "\n",
      "pred-> トム の 誕生 日 の 名前 を 思い出せ ない 。 EOS\n",
      "ans-> トム は メアリー の 誕生 日 に 何 か 特別 な こと を 計画 し て いる 。\n",
      "------------------\n",
      "src-> he wrote the report.\n",
      "\n",
      "pred-> 彼 は UNK を UNK し た 。 EOS\n",
      "ans-> 彼 は 報告 書 を 作文 し た 。\n",
      "------------------\n",
      "src-> can i change the route?\n",
      "\n",
      "pred-> UNK を UNK て い ます か 。 EOS\n",
      "ans-> 路線 の 変更 は でき ます か 。\n",
      "------------------\n",
      "src-> he is at his desk.\n",
      "\n",
      "pred-> 彼 は その 本 を 読ん で いる 。 EOS\n",
      "ans-> 彼 は 机 に 向かっ て いる 。\n",
      "------------------\n",
      "src-> war began five years later.\n",
      "\n",
      "pred-> 嵐 は 作物 に 多大 な 影響 を 与え た 。 EOS\n",
      "ans-> 5 年 後 に 戦争 が 始まっ た 。\n",
      "------------------\n",
      "src-> they formed themselves into a circle.\n",
      "\n",
      "pred-> 彼ら は UNK UNK だっ た 。 EOS\n",
      "ans-> 彼ら は 輪 に なっ た 。\n",
      "------------------\n",
      "src-> i used to play tennis in high school.\n",
      "\n",
      "pred-> 私 は いつも 学校 に 遅れる かも しれ ない 。 EOS\n",
      "ans-> 高校 時代 は よく テニス を し た もの です 。\n",
      "------------------\n",
      "src-> it was such a shock.\n",
      "\n",
      "pred-> それ が UNK だっ た 。 EOS\n",
      "ans-> それ は たいへん な ショック でし た 。\n",
      "------------------\n",
      "src-> whose umbrella is this?\n",
      "\n",
      "pred-> これ 誰 の ？ EOS\n",
      "ans-> これ 誰 の 傘 ？\n",
      "------------------\n",
      "src-> show me how.\n",
      "\n",
      "pred-> あなた の UNK を 見 て くれ ます 。 EOS\n",
      "ans-> どう やっ て やる の か 教え て 。\n",
      "------------------\n",
      "src-> did anybody get injured?\n",
      "\n",
      "pred-> 誰 か 怪我 し た ？ EOS\n",
      "ans-> 誰 か 怪我 し た ？\n",
      "------------------\n",
      "src-> if you calculate the electric field using this equation the result comes out like the following.\n",
      "\n",
      "pred-> 「 私 は 今日 の 午後 、 被災 し て 初めて だ から 、 彼ら が UNK まし た 。 EOS\n",
      "ans-> この 式 によって 電場 を 計算 し て やる と 、 結果 は 次 の よう に なる 。\n",
      "------------------\n",
      "src-> the travelers came from many lands.\n",
      "\n",
      "pred-> UNK に UNK が 鳴っ た 。 EOS\n",
      "ans-> 旅行 者 達 は いろいろ な 国 から やって来 た 。\n",
      "------------------\n",
      "src-> communications broke down.\n",
      "\n",
      "pred-> UNK を UNK 。 EOS\n",
      "ans-> 通信 手段 が 機能 し なく なっ た 。\n",
      "------------------\n",
      "src-> the sunny side of the hill is full of deciduous trees.\n",
      "\n",
      "pred-> １ ９ ９ ８ 年 前 の UNK は １ 日 に UNK れ て いる 。 EOS\n",
      "ans-> 丘 の 日 が 当っ て いる 部分 は 落葉樹 で いっぱい だ 。\n",
      "------------------\n",
      "src-> can you tell me how to get to the station?\n",
      "\n",
      "pred-> 駅 まで の 行き 方 を 教え て い た だけ ませ ん か 。 EOS\n",
      "ans-> 駅 へ どう 行っ たら 良い か を 教え て もらえ ませ ん か 。\n",
      "------------------\n",
      "src-> the old man was loved by everyone.\n",
      "\n",
      "pred-> その 知らせ に その 知らせ は UNK た 。 EOS\n",
      "ans-> その 老人 は 皆 に 愛さ れ て い た 。\n",
      "------------------\n",
      "src-> he pinched and scraped for many years to save money.\n",
      "\n",
      "pred-> 彼 は UNK に UNK を UNK う と 努力 し て いる 。 EOS\n",
      "ans-> 彼 は 金 を ためる ため 何 年間 も けちけち 倹約 し た 。\n",
      "------------------\n",
      "src-> the brain needs a continuous supply of blood.\n",
      "\n",
      "pred-> UNK は UNK やすい もの だ と 思う 。 EOS\n",
      "ans-> 小脳 は 血液 の 不断 の 供給 を 必要 と する 。\n",
      "------------------\n",
      "src-> his remark was really out of line.\n",
      "\n",
      "pred-> 彼 の UNK は UNK だ から 、 UNK 。 EOS\n",
      "ans-> 彼 の 意見 は 本当に 場違い だっ た 。\n",
      "------------------\n",
      "src-> im in trouble now.\n",
      "\n",
      "pred-> もう 一 回 やっ て み なさい 。 EOS\n",
      "ans-> 今 困っ て いる ん だ 。\n",
      "------------------\n",
      "src-> nobody knows whats going to happen.\n",
      "\n",
      "pred-> 誰 に も 言わ ない と 誓い ます か 。 EOS\n",
      "ans-> これから 何 が 起こる の か 、 誰 に も わから ない 。\n",
      "------------------\n",
      "src-> she has been watching television for three hours.\n",
      "\n",
      "pred-> 彼女 は 彼 に 会う の は 、 テレビ で 見 て い ます 。 EOS\n",
      "ans-> 彼女 は ３ 時間 テレビ を 見 続け て いる 。\n",
      "------------------\n",
      "src-> may i eat this bread?\n",
      "\n",
      "pred-> これ 、 UNK ない ん です か ？ EOS\n",
      "ans-> この パン 食べ て も いい ？\n",
      "------------------\n",
      "src-> see you.\n",
      "\n",
      "pred-> あなた に 会い まし た 。 EOS\n",
      "ans-> じゃ 、 また ねっ ！\n",
      "------------------\n",
      "src-> how long have you been looking for it?\n",
      "\n",
      "pred-> あなた は どこ に 住ん で いる の ？ EOS\n",
      "ans-> いつ から それ を お 探し です か 。\n",
      "------------------\n",
      "src-> the moon has set.\n",
      "\n",
      "pred-> UNK が 出 て い た 。 EOS\n",
      "ans-> 月 が 沈ん だ 。\n",
      "------------------\n",
      "src-> he looked into her eyes and suddenly went away.\n",
      "\n",
      "pred-> 彼女 は 目 を UNK て い た 。 EOS\n",
      "ans-> 彼 は 彼女 の 目 を 覗き 込む と 、 突然 立ち去っ た 。\n",
      "------------------\n",
      "src-> his grandmother looks healthy.\n",
      "\n",
      "pred-> 彼 の UNK は 好き で は あり ませ ん 。 EOS\n",
      "ans-> 彼 の おばあさん は 元気 そう です 。\n",
      "------------------\n",
      "src-> why do you love me?\n",
      "\n",
      "pred-> どうして あなた は 何 が 起こっ た ん です か ？ EOS\n",
      "ans-> なんで 私 の こと 好き な の ？\n",
      "------------------\n",
      "src-> i held on to the rope tightly so i wouldnt fall.\n",
      "\n",
      "pred-> 私 が 一 晩 中 踊る つもり だ と 言っ た 。 EOS\n",
      "ans-> 落ち ない よう に ロープ を 握りしめ た 。\n",
      "------------------\n",
      "src-> christmas is coming soon.\n",
      "\n",
      "pred-> もうすぐ クリスマス だ ね 。 EOS\n",
      "ans-> クリスマス が 近く なっ て き た 。\n",
      "------------------\n",
      "src-> we hurried to the train station.\n",
      "\n",
      "pred-> 私 たち が ここ に 駅 に 着い た 。 EOS\n",
      "ans-> 私 達 は 駅 へ 急い だ 。\n",
      "------------------\n",
      "src-> i have a good idea.\n",
      "\n",
      "pred-> いい 人 です 。 EOS\n",
      "ans-> いい 考え が あり ます 。\n",
      "------------------\n",
      "src-> theres nothing harder than a diamond.\n",
      "\n",
      "pred-> UNK は 、 UNK は まだ 生き て いる 。 EOS\n",
      "ans-> ダイヤモンド ほど 硬い もの は ない 。\n",
      "------------------\n",
      "src-> does it hurt a lot?\n",
      "\n",
      "pred-> ひどく 痛い の ？ EOS\n",
      "ans-> とっても 痛む ？\n",
      "------------------\n",
      "src-> thanks to his recommendation i was able to get a teaching job at a college in tokyo.\n",
      "\n",
      "pred-> 昔 の 友達 に 似 て い た が 、 私 が 大学 に 行き たい の を 見 て い た 。 EOS\n",
      "ans-> 彼 の 推薦 の おかげ で 、 私 は 東京 の 大学 で 教鞭 を とる こと が 出来 た 。\n",
      "------------------\n",
      "src-> theyre studying french and web design.\n",
      "\n",
      "pred-> 彼ら に は フランス語 が 話せる 人 を いる 。 EOS\n",
      "ans-> フランス語 と ウェブ・デザイン を 勉強 し て い ます 。\n",
      "------------------\n",
      "src-> five years have gone by since my father died.\n",
      "\n",
      "pred-> 父 が 私 の 仕事 を １ ０ ドル かかっ た 。 EOS\n",
      "ans-> 父 が 死ん で から 五 年 が 過ぎ た 。\n",
      "------------------\n",
      "src-> please write to me once in a while.\n",
      "\n",
      "pred-> 手紙 を 書い て ください 。 EOS\n",
      "ans-> たま に は 手紙 を 書い て ください 。\n",
      "------------------\n",
      "src-> mother has just gone shopping.\n",
      "\n",
      "pred-> 母 は 先週 大阪 を 行っ た 。 EOS\n",
      "ans-> 母 は ちょうど 買い物 に 出かけ た ところ です 。\n",
      "------------------\n",
      "src-> he was acquainted with everybody in town.\n",
      "\n",
      "pred-> 彼 は UNK に UNK を し た 。 EOS\n",
      "ans-> 彼 は 町 の 人 みんな と 付き合い が あっ た 。\n",
      "------------------\n",
      "src-> this bus can hold fifty people.\n",
      "\n",
      "pred-> この 歌 が 起こる の を 歌っ て いる 。 EOS\n",
      "ans-> この バス は 50 人 乗り です 。\n",
      "------------------\n",
      "src-> he loves traveling.\n",
      "\n",
      "pred-> 彼 は 目的 を 達成 し た 。 EOS\n",
      "ans-> 彼 は 旅行 が 大好き だ 。\n",
      "------------------\n",
      "src-> i should head out.\n",
      "\n",
      "pred-> UNK を し ます 。 EOS\n",
      "ans-> 出発 し なく て は いけ ない 。\n",
      "------------------\n",
      "src-> im afraid this data isnt reliable.\n",
      "\n",
      "pred-> 今日 の UNK は どこ に ある か わから ない 。 EOS\n",
      "ans-> この データ は 信用 でき ない と 思う 。\n",
      "------------------\n",
      "src-> a strange man was walking back and forth on the pavement.\n",
      "\n",
      "pred-> 警察 は その 事故 を UNK に 行っ た 。 EOS\n",
      "ans-> 見知らぬ 男 が 歩道 を 行っ たり 来 たり し て い た 。\n",
      "------------------\n",
      "src-> you have made all my dreams come true.\n",
      "\n",
      "pred-> あなた の UNK は 、 UNK に UNK て いる 。 EOS\n",
      "ans-> あなた は 私 の 夢 を 、 残らず 実現 さ せ て くれ た 。\n",
      "------------------\n",
      "src-> he lives in a large house.\n",
      "\n",
      "pred-> 彼 は 家 に い た ところ を UNK た 。 EOS\n",
      "ans-> 彼 は 広い 家 に 住ん で いる 。\n",
      "------------------\n",
      "src-> excuse me but could you lend me a pen?\n",
      "\n",
      "pred-> すみません が 、 ここ を UNK たい の です が 、 いかが です か 。 EOS\n",
      "ans-> すみません 、 ペン を 貸し て い た だけ ませ ん か ？\n",
      "------------------\n",
      "src-> were pretty pleased with that.\n",
      "\n",
      "pred-> 私 の UNK 、 UNK が 出 て いる 。 EOS\n",
      "ans-> 私 たち は それ で とても 満足 し て い ます 。\n",
      "------------------\n",
      "src-> stand still!\n",
      "\n",
      "pred-> 頭 が 痛い 。 EOS\n",
      "ans-> じっと し て ！\n",
      "------------------\n",
      "src-> could you please pass me the pepper?\n",
      "\n",
      "pred-> すみません が 胡椒 を とっ て 下さい ませ ん か 。 EOS\n",
      "ans-> コショウ を 取っ て もらえ ませ ん か 。\n",
      "------------------\n",
      "src-> tom and mary were dancing to the music.\n",
      "\n",
      "pred-> トム と メアリー は 二 人 とも 家 に いる 。 EOS\n",
      "ans-> トム と メアリー は 音楽 に 合わせ て 踊っ て い た 。\n",
      "------------------\n",
      "src-> nobody understands me.\n",
      "\n",
      "pred-> 誰 も い なかっ た 。 EOS\n",
      "ans-> 誰 も 私 の こと を 分かっ て くれ ない 。\n",
      "------------------\n",
      "src-> i dont know how to spell the word.\n",
      "\n",
      "pred-> 私 は あなた の UNK に は 、 何 が 起き て い ない の か 。 EOS\n",
      "ans-> その 単語 の スペル が わかり ませ ん 。\n",
      "------------------\n",
      "src-> i get the point.\n",
      "\n",
      "pred-> UNK は UNK だ 。 EOS\n",
      "ans-> 了解 し まし た 。\n",
      "------------------\n",
      "src-> he glanced at his watch.\n",
      "\n",
      "pred-> 彼 は UNK を UNK た 。 EOS\n",
      "ans-> 彼 は 時計 を チラッ と 見 た 。\n",
      "------------------\n",
      "src-> i cant stand him.\n",
      "\n",
      "pred-> 私 は 彼 に は 我慢 でき ない 。 EOS\n",
      "ans-> 私 は 彼 に がまん でき ない 。\n",
      "------------------\n",
      "src-> im sure i saw her two years ago.\n",
      "\n",
      "pred-> 私 は 彼女 の UNK に ぴったり UNK て い た 。 EOS\n",
      "ans-> 絶対 彼女 と 2 年 前 に 会っ てる と 思う 。\n",
      "------------------\n",
      "src-> he has an eye for art.\n",
      "\n",
      "pred-> 彼 は 仕事 を する 。 EOS\n",
      "ans-> 彼 は 絵 を 見る 目 が ある 。\n",
      "------------------\n",
      "src-> are there any cute girls in your class?\n",
      "\n",
      "pred-> どういう UNK だ よ ね ？ EOS\n",
      "ans-> クラス に かわいい 子 いる ？\n",
      "------------------\n",
      "src-> i made it myself.\n",
      "\n",
      "pred-> 私 は トム を 信じ て い ます 。 EOS\n",
      "ans-> 自分 で 作り まし た 。\n",
      "------------------\n",
      "src-> lets get started.\n",
      "\n",
      "pred-> さあ 、 UNK 。 EOS\n",
      "ans-> さあ 、 始め ましょ う 。\n",
      "------------------\n",
      "src-> take care.\n",
      "\n",
      "pred-> 気 を 付け て ね 。 EOS\n",
      "ans-> 気 を つけ て ！\n",
      "------------------\n",
      "src-> i dont know who he is.\n",
      "\n",
      "pred-> 彼 が 私 に は それ は 何 か する と 言っ た 。 EOS\n",
      "ans-> 彼 が 誰 だ か 知り ませ ん 。\n",
      "------------------\n",
      "src-> he remained silent.\n",
      "\n",
      "pred-> 彼 は 銀行 に 勤め て いる 。 EOS\n",
      "ans-> 彼 は 黙っ た まま だっ た 。\n",
      "------------------\n",
      "src-> dont lie. tell the truth.\n",
      "\n",
      "pred-> その こと について は 何 か 知っ て い ます 。 EOS\n",
      "ans-> うそ を つく な 、 正直 で あれ 。\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for src,pred,target in zip(val_data[src_col],ret,val_data[trg_col]):\n",
    "    print(\"src->\",src)\n",
    "    print()\n",
    "    print(\"pred->\",\" \".join(Langs[\"trg\"].id2word(pred)))\n",
    "    print(\"ans->\",target)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drEeGLeON8Jj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1-LSTM",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
