{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "sys.path.append(\"/Users/ueki/Desktop/work/jp_en_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.Seq2Seq_1 import build_model\n",
    "from utils.LangEn import LangEn\n",
    "from utils.LangJa import LangJa\n",
    "from utils.preprocess import loadLangs\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"corpus_file\":\"../data/jpn.txt\",\n",
    "    \"en_col\":\"description_en\",\n",
    "    \"jp_col\":\"description_jp\",\n",
    "    \"SOS_token\":1,\n",
    "    \"EOS_token\":0,\n",
    "    \"UNK_token\":2,\n",
    "    \"max_features\":5000,\n",
    "    \"MAX_LENGTH\":20,\n",
    "    \"train_size\":15000,\n",
    "    \"val_size\":100,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":20,\n",
    "    \"maxlen_enc\":20,\n",
    "    \"maxlen_dec\":20,\n",
    "    \"n_hidden\":400,\n",
    "    \"input_dim\":5000,\n",
    "    \"output_dim\":5000,\n",
    "    \"emb_dim\":300,\n",
    "    \"use_enc_emb\":False,\n",
    "    \"use_dec_emb\":False,\n",
    "    \"validation_split\":0.1,\n",
    "    \"trained_param_dir\":\"../trained_models/1_lstm_en_ja_01.hdf5\",\n",
    "    \"translate_length\":25,\n",
    "    \"en_W2V_FILE\" : \"../data/GoogleNews-vectors-negative300.bin.gz\",\n",
    "    \"jp_W2V_FILE\":\"../data/ja_data/ja.bin\",\n",
    "    \"src\":\"jp\",\n",
    "    \"trg\":\"en\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFjiCn22blbf"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,config):\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.epochs = config[\"epochs\"]\n",
    "        self.validation_split = config[\"validation_split\"]\n",
    "        self.trained_param_dir = config[\"trained_param_dir\"]\n",
    "        self.output_dim = config[\"output_dim\"]\n",
    "        self.hist =None\n",
    "    def train(self,e_input,d_input,target):\n",
    "        print(\"#1 train procedure start\")\n",
    "        model,_,_ = build_model(config)\n",
    "        model.summary()\n",
    "        \n",
    "        if os.path.isfile(self.trained_param_dir) and False: #モデルの学習済みパラメータ\n",
    "            print(\"2-1? load param\")\n",
    "            model.load_weights(self.trained_param_dir)\n",
    "        else:\n",
    "            print(\"no_emb\")\n",
    "        print(\"#6 start training\")\n",
    "        \n",
    "        target_categorical = np_utils.to_categorical(output_target_padded,self.output_dim)\n",
    "       \n",
    "        self.hist=model.fit([e_input,d_input],target_categorical,epochs=self.epochs,batch_size=self.batch_size,validation_split=self.validation_split)\n",
    "        print(\"#9 save_param\")\n",
    "        model.save_weights(self.trained_param_dir)\n",
    "        #return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self,config):\n",
    "        self.translate_length = config[\"translate_length\"]\n",
    "        self.trained_param_dir = config[\"trained_param_dir\"]\n",
    "        self.model,self.encoder,self.decoder = build_model(config,test=True)\n",
    "        self.model.load_weights(self.trained_param_dir)\n",
    "    ## 翻訳文生成\n",
    "    def _translate(self,e_input):\n",
    "        #encode input to vec\n",
    "        #encoder_outputs,state_h_1,state_c_1 = self.encoder.predict(e_input)\n",
    "        #states_values=[state_h_1,state_c_1]\n",
    "        encoder_outputs,*states_values = self.encoder.predict(e_input)\n",
    "        \n",
    "        #first token\n",
    "        target_seq=np.zeros((1,1))\n",
    "        target_seq[0,0] = config[\"SOS_token\"]\n",
    "        \n",
    "        decoded_sentence=[]\n",
    "        for i in range(0,self.translate_length):\n",
    "            #output_tokens,h1,c1 = self.decoder.predict([target_seq]+states_values)\n",
    "            output_tokens,*states_values = self.decoder.predict([target_seq]+states_values)\n",
    "            \n",
    "            sampled_token_index=np.argmax(output_tokens[0,0,:])\n",
    "            if sampled_token_index==config[\"EOS_token\"]:\n",
    "                decoded_sentence.append(config[\"EOS_token\"])\n",
    "                break\n",
    "            else:\n",
    "                target_seq[0,0] = sampled_token_index\n",
    "                #states_values =[h1,c1]\n",
    "                decoded_sentence.append(sampled_token_index)\n",
    "        return decoded_sentence                                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def translate_demo(self,src_data_id_seq):\n",
    "        ret=[]\n",
    "        for src in src_data_id_seq:\n",
    "            id_seq_mat = np.array([src])\n",
    "            pred_id_padded = sequence.pad_sequences(id_seq_mat,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "            pred=self._translate(pred_id_padded)\n",
    "            ret.append(pred)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_en_emb(config):\n",
    "    en_word2vec= KeyedVectors.load_word2vec_format(config[\"en_W2V_FILE\"],binary=True)\n",
    "    en_EMBEDDING_DIM=config[\"emb_dim\"]\n",
    "    #n_word<max_featureの時にerrになるよ\n",
    "    vocabulary_size=min(EN_lang.n_words,config[\"max_features\"])\n",
    "    en_embedding_matrix = np.zeros((vocabulary_size, en_EMBEDDING_DIM))\n",
    "    print(\"voc->\",vocabulary_size)\n",
    "    cnt=0\n",
    "    for word, i in EN_lang.word2index.items():\n",
    "        if   i==0 or i==1 or i ==2:\n",
    "            continue\n",
    "        try:\n",
    "            en_embedding_vector = en_word2vec[word]\n",
    "            en_embedding_matrix[i] = en_embedding_vector\n",
    "        except KeyError:\n",
    "            cnt+=1\n",
    "            en_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),en_EMBEDDING_DIM)\n",
    "    print(\"UNK_rate\",cnt/i)\n",
    "    del en_word2vec\n",
    "    gc.collect()\n",
    "    return en_embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "QA-6hirSN7c3",
    "outputId": "e9b07f89-37e4-4be1-e085-9e7cc53a4a20"
   },
   "outputs": [],
   "source": [
    "def build_jp_emb(config):\n",
    "    jp_word2vec= model = Word2Vec.load(config[\"jp_W2V_FILE\"])\n",
    "    jp_EMBEDDING_DIM=config[\"emb_dim\"]\n",
    "    vocabulary_size=min(JP_lang.n_words,config[\"max_features\"])\n",
    "    jp_embedding_matrix = np.zeros((vocabulary_size, jp_EMBEDDING_DIM))\n",
    "    print(\"voc->\",vocabulary_size)\n",
    "    cnt=0\n",
    "    for word, i in JP_lang.word2index.items():\n",
    "        if   i==0 or i==1 or i ==2:\n",
    "            continue\n",
    "        try:\n",
    "            jp_embedding_vector = jp_word2vec[word]\n",
    "            jp_embedding_matrix[i] = jp_embedding_vector\n",
    "        except KeyError:\n",
    "            cnt+=1\n",
    "            jp_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),jp_EMBEDDING_DIM)\n",
    "    print(\"UNK/rate->\",cnt/i)\n",
    "\n",
    "    del jp_word2vec\n",
    "    gc.collect()\n",
    "    return jp_embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h6V9OfqpcQn"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YmVIGLgYpdn2",
    "outputId": "703c3b2f-347a-4377-af52-f1ce4717b447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lines\n"
     ]
    }
   ],
   "source": [
    "data=loadLangs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FCy7THnpdim"
   },
   "outputs": [],
   "source": [
    "val_data = data[config[\"train_size\"]:config[\"train_size\"]+config[\"val_size\"]]\n",
    "data = data[:config[\"train_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsa0heCPpow7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 15:55:05.671116 4342552000 toolwrapper.py:77] stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    }
   ],
   "source": [
    "EN_lang = LangEn(config)\n",
    "JP_lang = LangJa(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWurNSGQpoug"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"en_col\"]]:\n",
    "    EN_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJgN_yKjposQ"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"jp_col\"]]:\n",
    "    JP_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5Tz-dt4YJUu"
   },
   "source": [
    "## input の加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"src\"]==\"jp\":\n",
    "    src_col=config[\"jp_col\"]\n",
    "    trg_col=config[\"en_col\"]\n",
    "    Langs={\"src\":JP_lang,\"trg\":EN_lang}\n",
    "else:\n",
    "    src_col=config[\"en_col\"]\n",
    "    trg_col=config[\"jp_col\"]\n",
    "    Langs={\"trg\":JP_lang,\"src\":EN_lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZkMItuoprY2"
   },
   "outputs": [],
   "source": [
    "input_en = data[src_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6IBzGaKvpYS"
   },
   "outputs": [],
   "source": [
    "input_source_lang=data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
    "input_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x,target=True))\n",
    "output_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNv2-2QGwJOP"
   },
   "outputs": [],
   "source": [
    "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "output_target_padded=sequence.pad_sequences(output_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 15:55:09.286256 4342552000 deprecation_wrapper.py:119] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0802 15:55:09.311437 4342552000 deprecation_wrapper.py:119] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0802 15:55:09.312656 4342552000 deprecation_wrapper.py:119] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0802 15:55:09.431483 4342552000 deprecation_wrapper.py:119] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 train procedure start\n",
      "#3 encoder\n",
      "#4 decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 15:55:10.714529 4342552000 deprecation_wrapper.py:119] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0802 15:55:10.824490 4342552000 deprecation_wrapper.py:119] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5\n",
      "#6\n",
      "#7\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 300)      1500000     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 20, 300)      1200        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 300)      1500000     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_LSTM_fw1 (LSTM)         [(None, 20, 400), (N 1121600     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_LSTM_bw1 (LSTM)         [(None, 20, 400), (N 1121600     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 20, 300)      1200        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 400)          0           encoder_LSTM_fw1[0][1]           \n",
      "                                                                 encoder_LSTM_bw1[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 400)          0           encoder_LSTM_fw1[0][2]           \n",
      "                                                                 encoder_LSTM_bw1[0][2]           \n",
      "__________________________________________________________________________________________________\n",
      "decode_LSTM1 (LSTM)             [(None, 20, 400), (N 1121600     batch_normalization_2[0][0]      \n",
      "                                                                 add_2[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_Dense (Dense)           (None, 20, 5000)     2005000     decode_LSTM1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 8,372,200\n",
      "Trainable params: 8,371,000\n",
      "Non-trainable params: 1,200\n",
      "__________________________________________________________________________________________________\n",
      "no_emb\n",
      "#6 start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 15:55:11.716564 4342552000 deprecation.py:323] From /Users/ueki/.pyenv/versions/3.7.3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "13500/13500 [==============================] - 212s 16ms/step - loss: 2.5350 - categorical_accuracy: 0.6608 - val_loss: 1.9770 - val_categorical_accuracy: 0.6870\n",
      "Epoch 2/20\n",
      "13500/13500 [==============================] - 252s 19ms/step - loss: 1.8819 - categorical_accuracy: 0.7011 - val_loss: 1.7871 - val_categorical_accuracy: 0.7017\n",
      "Epoch 3/20\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 1.7049 - categorical_accuracy: 0.7147 - val_loss: 1.6717 - val_categorical_accuracy: 0.7140\n",
      "Epoch 4/20\n",
      "13500/13500 [==============================] - 239s 18ms/step - loss: 1.5695 - categorical_accuracy: 0.7274 - val_loss: 1.5966 - val_categorical_accuracy: 0.7202\n",
      "Epoch 5/20\n",
      "13500/13500 [==============================] - 254s 19ms/step - loss: 1.4461 - categorical_accuracy: 0.7422 - val_loss: 1.5253 - val_categorical_accuracy: 0.7313\n",
      "Epoch 6/20\n",
      "13500/13500 [==============================] - 220s 16ms/step - loss: 1.3333 - categorical_accuracy: 0.7540 - val_loss: 1.4723 - val_categorical_accuracy: 0.7369\n",
      "Epoch 7/20\n",
      "13500/13500 [==============================] - 221s 16ms/step - loss: 1.2344 - categorical_accuracy: 0.7648 - val_loss: 1.4414 - val_categorical_accuracy: 0.7415\n",
      "Epoch 8/20\n",
      "13500/13500 [==============================] - 226s 17ms/step - loss: 1.1408 - categorical_accuracy: 0.7767 - val_loss: 1.4066 - val_categorical_accuracy: 0.7475\n",
      "Epoch 9/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 1.0545 - categorical_accuracy: 0.7889 - val_loss: 1.3868 - val_categorical_accuracy: 0.7526\n",
      "Epoch 10/20\n",
      "13500/13500 [==============================] - 218s 16ms/step - loss: 0.9729 - categorical_accuracy: 0.8007 - val_loss: 1.3701 - val_categorical_accuracy: 0.7565\n",
      "Epoch 11/20\n",
      "13500/13500 [==============================] - 217s 16ms/step - loss: 0.8971 - categorical_accuracy: 0.8127 - val_loss: 1.3662 - val_categorical_accuracy: 0.7564\n",
      "Epoch 12/20\n",
      "13500/13500 [==============================] - 216s 16ms/step - loss: 0.8275 - categorical_accuracy: 0.8250 - val_loss: 1.3616 - val_categorical_accuracy: 0.7596\n",
      "Epoch 13/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 0.7618 - categorical_accuracy: 0.8372 - val_loss: 1.3630 - val_categorical_accuracy: 0.7606\n",
      "Epoch 14/20\n",
      "13500/13500 [==============================] - 231s 17ms/step - loss: 0.7004 - categorical_accuracy: 0.8491 - val_loss: 1.3655 - val_categorical_accuracy: 0.7620\n",
      "Epoch 15/20\n",
      "13500/13500 [==============================] - 231s 17ms/step - loss: 0.6440 - categorical_accuracy: 0.8606 - val_loss: 1.3613 - val_categorical_accuracy: 0.7649\n",
      "Epoch 16/20\n",
      "13500/13500 [==============================] - 233s 17ms/step - loss: 0.5914 - categorical_accuracy: 0.8725 - val_loss: 1.3712 - val_categorical_accuracy: 0.7662\n",
      "Epoch 17/20\n",
      "13500/13500 [==============================] - 252s 19ms/step - loss: 0.5404 - categorical_accuracy: 0.8834 - val_loss: 1.3745 - val_categorical_accuracy: 0.7663\n",
      "Epoch 18/20\n",
      "13500/13500 [==============================] - 237s 18ms/step - loss: 0.4944 - categorical_accuracy: 0.8932 - val_loss: 1.3870 - val_categorical_accuracy: 0.7647\n",
      "Epoch 19/20\n",
      "13500/13500 [==============================] - 249s 18ms/step - loss: 0.4505 - categorical_accuracy: 0.9035 - val_loss: 1.3928 - val_categorical_accuracy: 0.7676\n",
      "Epoch 20/20\n",
      "13500/13500 [==============================] - 246s 18ms/step - loss: 0.4097 - categorical_accuracy: 0.9127 - val_loss: 1.4072 - val_categorical_accuracy: 0.7674\n",
      "#9 save_param\n"
     ]
    }
   ],
   "source": [
    "trainer.train(input_source_padded,input_target_padded,output_target_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m8_2NQDMYRrV",
    "outputId": "577b1ea5-a7c7-4601-983f-e29ad73d26ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del trainer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5khAA1aymGoX"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N9v_wwtqu6E"
   },
   "outputs": [],
   "source": [
    "val_data_id = val_data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aA--RWDUHjPB",
    "outputId": "ac683833-7751-43e7-fd89-01a41abff1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15043                 [4781, 601, 22, 203, 260, 261, 5, 0]\n",
       "15044                    [6, 9, 2, 11, 1519, 14, 53, 5, 0]\n",
       "15045    [283, 1082, 293, 484, 7, 2886, 30, 194, 11, 13...\n",
       "15046                            [21, 22, 847, 2, 4, 5, 0]\n",
       "15047    [743, 31, 16, 3205, 2, 274, 26, 513, 13, 19, 7...\n",
       "15048               [176, 22, 2, 7, 2, 11, 2317, 34, 5, 0]\n",
       "15049                        [2, 26, 2, 16, 525, 34, 5, 0]\n",
       "15050    [31, 22, 54, 1250, 9, 2, 39, 22, 203, 260, 261...\n",
       "15051             [3, 22, 121, 93, 3147, 13, 19, 66, 5, 0]\n",
       "15052      [171, 22, 1598, 41, 42, 11, 480, 151, 15, 5, 0]\n",
       "Name: description_jp, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 encoder\n",
      "#4 decoder\n",
      "#5\n",
      "#6\n",
      "#7\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = translator.translate_demo(val_data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0w7srpDEx_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src-> 急ぐ 必要 は あり ませ ん 。\n",
      "\n",
      "pred-> you dont need to hurry . EOS\n",
      "ans-> theres no need to hurry.\n",
      "------------------\n",
      "src-> あなた の バンド に 入り たい な 。\n",
      "\n",
      "pred-> id like to stay a present . EOS\n",
      "ans-> i want to join your band.\n",
      "------------------\n",
      "src-> その 子 から 目 を 離さ ない よう に し なけれ ば いけ ない 。\n",
      "\n",
      "pred-> dont judge people by their appearance . EOS\n",
      "ans-> you must keep an eye on the child.\n",
      "------------------\n",
      "src-> 彼 は 音楽 狂 だ 。\n",
      "\n",
      "pred-> he was in a UNK . EOS\n",
      "ans-> he is mad about music.\n",
      "------------------\n",
      "src-> もし 彼女 が もう少し 我慢強かっ たら 、 成功 し て い た だろ う に 。\n",
      "\n",
      "pred-> if it were no taxis she could have come in a hurry . EOS\n",
      "ans-> with a little more patience she would have succeeded.\n",
      "------------------\n",
      "src-> 彼ら は フェンス を 緑色 に 塗っ た 。\n",
      "\n",
      "pred-> they abandoned the UNK of UNK . EOS\n",
      "ans-> they painted the fence green.\n",
      "------------------\n",
      "src-> 先月 、 集会 が あっ た 。\n",
      "\n",
      "pred-> the ship was bound for cairo . EOS\n",
      "ans-> there was a convention last month.\n",
      "------------------\n",
      "src-> 彼女 は この 会社 の 正社員 で は あり ませ ん 。\n",
      "\n",
      "pred-> she is able to speak french at all . EOS\n",
      "ans-> shes not a fulltime employee of this company.\n",
      "------------------\n",
      "src-> トム は メアリー と 喧嘩 し て いる 。\n",
      "\n",
      "pred-> tom looks like tom . EOS\n",
      "ans-> tom is arguing with mary.\n",
      "------------------\n",
      "src-> 今日 は 長い 一 日 に なり そう です 。\n",
      "\n",
      "pred-> its a good crop if this morning so . EOS\n",
      "ans-> it looks like today will be a long day.\n",
      "------------------\n",
      "src-> トム は 一 晩 中 泣き明かし た 。\n",
      "\n",
      "pred-> tom walked in the room . EOS\n",
      "ans-> tom cried all night long.\n",
      "------------------\n",
      "src-> トム は 欲しく なかっ た 。\n",
      "\n",
      "pred-> tom didnt want . EOS\n",
      "ans-> tom didnt want it.\n",
      "------------------\n",
      "src-> 彼女 の スピーチ で 感動 し て 泣い た 。\n",
      "\n",
      "pred-> she UNK the new novel . EOS\n",
      "ans-> i was moved to tears by her speech.\n",
      "------------------\n",
      "src-> 彼 の 妻 の 姿 は どこ に も 見え なかっ た 。\n",
      "\n",
      "pred-> his house was so far from him . EOS\n",
      "ans-> his wife was nowhere to be seen.\n",
      "------------------\n",
      "src-> 10 月 は ボストン に い た 。\n",
      "\n",
      "pred-> the storm has gradually abated . EOS\n",
      "ans-> in october i was in boston.\n",
      "------------------\n",
      "src-> 私 は 招待 さ れ た パーティー に は 必ず 出席 する 。\n",
      "\n",
      "pred-> i was able to swim across the river . EOS\n",
      "ans-> i go to any party i am invited to.\n",
      "------------------\n",
      "src-> 今年 、 注目 し て いる 選手 は 誰 です か 。\n",
      "\n",
      "pred-> is this a book whose name is ? EOS\n",
      "ans-> which player are you paying the most attention to this year?\n",
      "------------------\n",
      "src-> 彼 は 使い きれ ない ほど の 金 を 稼ぐ 。\n",
      "\n",
      "pred-> he is not able to speak to the new project . EOS\n",
      "ans-> he earns more money than he can spend.\n",
      "------------------\n",
      "src-> できる 限り の こと は し て みる つもり だ 。\n",
      "\n",
      "pred-> i am going to go to bed early this evening . EOS\n",
      "ans-> i intend to try doing everything i can.\n",
      "------------------\n",
      "src-> あなた に は 本当 の こと を 言い たく ない の 。\n",
      "\n",
      "pred-> you dont want to talk to you ? EOS\n",
      "ans-> i dont want to tell you the truth.\n",
      "------------------\n",
      "src-> かなり 痛む の です か 。\n",
      "\n",
      "pred-> are you a japanese citizen ? EOS\n",
      "ans-> will it hurt a lot?\n",
      "------------------\n",
      "src-> テスト で 一 問 も 答え られ なかっ た 。\n",
      "\n",
      "pred-> i couldnt go out this hot UNK . EOS\n",
      "ans-> i couldnt answer any questions on the test.\n",
      "------------------\n",
      "src-> トム は 老人 の よう な 話し方 を する 。\n",
      "\n",
      "pred-> tom is able to swim well tom . EOS\n",
      "ans-> tom talks like an old man.\n",
      "------------------\n",
      "src-> 彼 は 本 を 読む の が 好き だ 。\n",
      "\n",
      "pred-> he likes coffee without his homework . EOS\n",
      "ans-> he likes to read books.\n",
      "------------------\n",
      "src-> マーガリン を バター と 間違え た の ？\n",
      "\n",
      "pred-> how much did you get on the trip ? EOS\n",
      "ans-> did you mistake the margarine for butter?\n",
      "------------------\n",
      "src-> なんて こと なかっ た 。\n",
      "\n",
      "pred-> everyone in it . EOS\n",
      "ans-> i thought nothing of it.\n",
      "------------------\n",
      "src-> 平行 線 は 交差 し ませ ん 。\n",
      "\n",
      "pred-> the ship sank to the bottom . EOS\n",
      "ans-> parallel lines do not intersect each other.\n",
      "------------------\n",
      "src-> 正確 に 言う と 私 は 大学 講師 です 。\n",
      "\n",
      "pred-> its about time i went to the barbers . EOS\n",
      "ans-> im actually a university teacher.\n",
      "------------------\n",
      "src-> 彼 が 死ん で から 十 年 に なり ます 。\n",
      "\n",
      "pred-> he has been studying for three years . EOS\n",
      "ans-> ten years have passed since he died.\n",
      "------------------\n",
      "src-> お金 が 幸福 を もたらす と は 限ら ない 。\n",
      "\n",
      "pred-> that is the way of us that . EOS\n",
      "ans-> money does not always bring happiness.\n",
      "------------------\n",
      "src-> 彼女 は その ニュース を 聞い て 驚い た 。\n",
      "\n",
      "pred-> she was surprised that she was able to swim . EOS\n",
      "ans-> she was surprised at the news.\n",
      "------------------\n",
      "src-> やつ は 僕 を 裏切っ た ん だ ！\n",
      "\n",
      "pred-> were the cold yesterday morning . EOS\n",
      "ans-> he stabbed me in the back!\n",
      "------------------\n",
      "src-> トム は メアリー の 誕生 日 に 何 か 特別 な こと を 計画 し て いる 。\n",
      "\n",
      "pred-> tom and mary are vegetarians . EOS\n",
      "ans-> toms planning something special for marys birthday.\n",
      "------------------\n",
      "src-> 彼 は 報告 書 を 作文 し た 。\n",
      "\n",
      "pred-> he took off his bike . EOS\n",
      "ans-> he wrote the report.\n",
      "------------------\n",
      "src-> 路線 の 変更 は でき ます か 。\n",
      "\n",
      "pred-> can you speak french ? EOS\n",
      "ans-> can i change the route?\n",
      "------------------\n",
      "src-> 彼 は 机 に 向かっ て いる 。\n",
      "\n",
      "pred-> he is a man . EOS\n",
      "ans-> he is at his desk.\n",
      "------------------\n",
      "src-> 5 年 後 に 戦争 が 始まっ た 。\n",
      "\n",
      "pred-> we have already finished the work . EOS\n",
      "ans-> war began five years later.\n",
      "------------------\n",
      "src-> 彼ら は 輪 に なっ た 。\n",
      "\n",
      "pred-> they married him . EOS\n",
      "ans-> they formed themselves into a circle.\n",
      "------------------\n",
      "src-> 高校 時代 は よく テニス を し た もの です 。\n",
      "\n",
      "pred-> my mother made a baby in this morning . EOS\n",
      "ans-> i used to play tennis in high school.\n",
      "------------------\n",
      "src-> それ は たいへん な ショック でし た 。\n",
      "\n",
      "pred-> thats a bit of a problem . EOS\n",
      "ans-> it was such a shock.\n",
      "------------------\n",
      "src-> これ 誰 の 傘 ？\n",
      "\n",
      "pred-> who can i come ? EOS\n",
      "ans-> whose umbrella is this?\n",
      "------------------\n",
      "src-> どう やっ て やる の か 教え て 。\n",
      "\n",
      "pred-> tell me what you did . EOS\n",
      "ans-> show me how.\n",
      "------------------\n",
      "src-> 誰 か 怪我 し た ？\n",
      "\n",
      "pred-> did anybody hurt ? EOS\n",
      "ans-> did anybody get injured?\n",
      "------------------\n",
      "src-> この 式 によって 電場 を 計算 し て やる と 、 結果 は 次 の よう に なる 。\n",
      "\n",
      "pred-> if you had a UNK written by a UNK in this morning and want to do . EOS\n",
      "ans-> if you calculate the electric field using this equation the result comes out like the following.\n",
      "------------------\n",
      "src-> 旅行 者 達 は いろいろ な 国 から やって来 た 。\n",
      "\n",
      "pred-> a storm prevented us from a good nights from bad . EOS\n",
      "ans-> the travelers came from many lands.\n",
      "------------------\n",
      "src-> 通信 手段 が 機能 し なく なっ た 。\n",
      "\n",
      "pred-> the UNK ceremony was performed in the morning . EOS\n",
      "ans-> communications broke down.\n",
      "------------------\n",
      "src-> 丘 の 日 が 当っ て いる 部分 は 落葉樹 で いっぱい だ 。\n",
      "\n",
      "pred-> the population of the world is increasing even in a UNK . EOS\n",
      "ans-> the sunny side of the hill is full of deciduous trees.\n",
      "------------------\n",
      "src-> 駅 へ どう 行っ たら 良い か を 教え て もらえ ませ ん か 。\n",
      "\n",
      "pred-> how would you please tell me how to get to the station ? EOS\n",
      "ans-> can you tell me how to get to the station?\n",
      "------------------\n",
      "src-> その 老人 は 皆 に 愛さ れ て い た 。\n",
      "\n",
      "pred-> the old man was almost hit by a car . EOS\n",
      "ans-> the old man was loved by everyone.\n",
      "------------------\n",
      "src-> 彼 は 金 を ためる ため 何 年間 も けちけち 倹約 し た 。\n",
      "\n",
      "pred-> he made a new babysitter on the hill . EOS\n",
      "ans-> he pinched and scraped for many years to save money.\n",
      "------------------\n",
      "src-> 小脳 は 血液 の 不断 の 供給 を 必要 と する 。\n",
      "\n",
      "pred-> the teacher is always on the top of the top of the world . EOS\n",
      "ans-> the brain needs a continuous supply of blood.\n",
      "------------------\n",
      "src-> 彼 の 意見 は 本当に 場違い だっ た 。\n",
      "\n",
      "pred-> i was caught in a shower and he is on . EOS\n",
      "ans-> his remark was really out of line.\n",
      "------------------\n",
      "src-> 今 困っ て いる ん だ 。\n",
      "\n",
      "pred-> im busy now . EOS\n",
      "ans-> im in trouble now.\n",
      "------------------\n",
      "src-> これから 何 が 起こる の か 、 誰 に も わから ない 。\n",
      "\n",
      "pred-> no one knows the reason why . EOS\n",
      "ans-> nobody knows whats going to happen.\n",
      "------------------\n",
      "src-> 彼女 は ３ 時間 テレビ を 見 続け て いる 。\n",
      "\n",
      "pred-> she is always busy in the morning . EOS\n",
      "ans-> she has been watching television for three hours.\n",
      "------------------\n",
      "src-> この パン 食べ て も いい ？\n",
      "\n",
      "pred-> is this edible ? EOS\n",
      "ans-> may i eat this bread?\n",
      "------------------\n",
      "src-> じゃ 、 また ねっ ！\n",
      "\n",
      "pred-> its already seven . EOS\n",
      "ans-> see you.\n",
      "------------------\n",
      "src-> いつ から それ を お 探し です か 。\n",
      "\n",
      "pred-> is it true that your family will come ? EOS\n",
      "ans-> how long have you been looking for it?\n",
      "------------------\n",
      "src-> 月 が 沈ん だ 。\n",
      "\n",
      "pred-> the moon is out on the table . EOS\n",
      "ans-> the moon has set.\n",
      "------------------\n",
      "src-> 彼 は 彼女 の 目 を 覗き 込む と 、 突然 立ち去っ た 。\n",
      "\n",
      "pred-> he was UNK to her parents for her hand . EOS\n",
      "ans-> he looked into her eyes and suddenly went away.\n",
      "------------------\n",
      "src-> 彼 の おばあさん は 元気 そう です 。\n",
      "\n",
      "pred-> my father is good at home . EOS\n",
      "ans-> his grandmother looks healthy.\n",
      "------------------\n",
      "src-> なんで 私 の こと 好き な の ？\n",
      "\n",
      "pred-> why do you like your name ? EOS\n",
      "ans-> why do you love me?\n",
      "------------------\n",
      "src-> 落ち ない よう に ロープ を 握りしめ た 。\n",
      "\n",
      "pred-> i put the luggage down . EOS\n",
      "ans-> i held on to the rope tightly so i wouldnt fall.\n",
      "------------------\n",
      "src-> クリスマス が 近く なっ て き た 。\n",
      "\n",
      "pred-> christmas is soon . EOS\n",
      "ans-> christmas is coming soon.\n",
      "------------------\n",
      "src-> 私 達 は 駅 へ 急い だ 。\n",
      "\n",
      "pred-> we were in the train . EOS\n",
      "ans-> we hurried to the train station.\n",
      "------------------\n",
      "src-> いい 考え が あり ます 。\n",
      "\n",
      "pred-> that is a beautiful . EOS\n",
      "ans-> i have a good idea.\n",
      "------------------\n",
      "src-> ダイヤモンド ほど 硬い もの は ない 。\n",
      "\n",
      "pred-> UNK is a UNK of UNK . EOS\n",
      "ans-> theres nothing harder than a diamond.\n",
      "------------------\n",
      "src-> とっても 痛む ？\n",
      "\n",
      "pred-> how much is this ? EOS\n",
      "ans-> does it hurt a lot?\n",
      "------------------\n",
      "src-> 彼 の 推薦 の おかげ で 、 私 は 東京 の 大学 で 教鞭 を とる こと が 出来 た 。\n",
      "\n",
      "pred-> having met him a few days and john and his wife died . EOS\n",
      "ans-> thanks to his recommendation i was able to get a teaching job at a college in tokyo.\n",
      "------------------\n",
      "src-> フランス語 と ウェブ・デザイン を 勉強 し て い ます 。\n",
      "\n",
      "pred-> im studying french and web design . EOS\n",
      "ans-> theyre studying french and web design.\n",
      "------------------\n",
      "src-> 父 が 死ん で から 五 年 が 過ぎ た 。\n",
      "\n",
      "pred-> the boy broke out of my shoes . EOS\n",
      "ans-> five years have gone by since my father died.\n",
      "------------------\n",
      "src-> たま に は 手紙 を 書い て ください 。\n",
      "\n",
      "pred-> please write me at that . EOS\n",
      "ans-> please write to me once in a while.\n",
      "------------------\n",
      "src-> 母 は ちょうど 買い物 に 出かけ た ところ です 。\n",
      "\n",
      "pred-> my mother was born in the morning . EOS\n",
      "ans-> mother has just gone shopping.\n",
      "------------------\n",
      "src-> 彼 は 町 の 人 みんな と 付き合い が あっ た 。\n",
      "\n",
      "pred-> he had a quarrel with him over the river . EOS\n",
      "ans-> he was acquainted with everybody in town.\n",
      "------------------\n",
      "src-> この バス は 50 人 乗り です 。\n",
      "\n",
      "pred-> this sentence is in the garden . EOS\n",
      "ans-> this bus can hold fifty people.\n",
      "------------------\n",
      "src-> 彼 は 旅行 が 大好き だ 。\n",
      "\n",
      "pred-> he likes to travel alone . EOS\n",
      "ans-> he loves traveling.\n",
      "------------------\n",
      "src-> 出発 し なく て は いけ ない 。\n",
      "\n",
      "pred-> you dont have to go . EOS\n",
      "ans-> i should head out.\n",
      "------------------\n",
      "src-> この データ は 信用 でき ない と 思う 。\n",
      "\n",
      "pred-> i cant see you this afternoon . EOS\n",
      "ans-> im afraid this data isnt reliable.\n",
      "------------------\n",
      "src-> 見知らぬ 男 が 歩道 を 行っ たり 来 たり し て い た 。\n",
      "\n",
      "pred-> a man who was in danger of losing my life . EOS\n",
      "ans-> a strange man was walking back and forth on the pavement.\n",
      "------------------\n",
      "src-> あなた は 私 の 夢 を 、 残らず 実現 さ せ て くれ た 。\n",
      "\n",
      "pred-> i asked my mind to have your family . EOS\n",
      "ans-> you have made all my dreams come true.\n",
      "------------------\n",
      "src-> 彼 は 広い 家 に 住ん で いる 。\n",
      "\n",
      "pred-> he is able to swim across the river . EOS\n",
      "ans-> he lives in a large house.\n",
      "------------------\n",
      "src-> すみません 、 ペン を 貸し て い た だけ ませ ん か ？\n",
      "\n",
      "pred-> could you please wait a little while i ? EOS\n",
      "ans-> excuse me but could you lend me a pen?\n",
      "------------------\n",
      "src-> 私 たち は それ で とても 満足 し て い ます 。\n",
      "\n",
      "pred-> we are very good friends . EOS\n",
      "ans-> were pretty pleased with that.\n",
      "------------------\n",
      "src-> じっと し て ！\n",
      "\n",
      "pred-> dont get in touch . EOS\n",
      "ans-> stand still!\n",
      "------------------\n",
      "src-> コショウ を 取っ て もらえ ませ ん か 。\n",
      "\n",
      "pred-> could you please wait a little bit longer ? EOS\n",
      "ans-> could you please pass me the pepper?\n",
      "------------------\n",
      "src-> トム と メアリー は 音楽 に 合わせ て 踊っ て い た 。\n",
      "\n",
      "pred-> tom was arrested because of the accident on his wife . EOS\n",
      "ans-> tom and mary were dancing to the music.\n",
      "------------------\n",
      "src-> 誰 も 私 の こと を 分かっ て くれ ない 。\n",
      "\n",
      "pred-> everyone can do it any more . EOS\n",
      "ans-> nobody understands me.\n",
      "------------------\n",
      "src-> その 単語 の スペル が わかり ませ ん 。\n",
      "\n",
      "pred-> i cant get in the refrigerator . EOS\n",
      "ans-> i dont know how to spell the word.\n",
      "------------------\n",
      "src-> 了解 し まし た 。\n",
      "\n",
      "pred-> i was UNK . EOS\n",
      "ans-> i get the point.\n",
      "------------------\n",
      "src-> 彼 は 時計 を チラッ と 見 た 。\n",
      "\n",
      "pred-> he had to watch tv at all . EOS\n",
      "ans-> he glanced at his watch.\n",
      "------------------\n",
      "src-> 私 は 彼 に がまん でき ない 。\n",
      "\n",
      "pred-> i cant trust him . EOS\n",
      "ans-> i cant stand him.\n",
      "------------------\n",
      "src-> 絶対 彼女 と 2 年 前 に 会っ てる と 思う 。\n",
      "\n",
      "pred-> i think that she is UNK her house . EOS\n",
      "ans-> im sure i saw her two years ago.\n",
      "------------------\n",
      "src-> 彼 は 絵 を 見る 目 が ある 。\n",
      "\n",
      "pred-> he has a cheerful disposition . EOS\n",
      "ans-> he has an eye for art.\n",
      "------------------\n",
      "src-> クラス に かわいい 子 いる ？\n",
      "\n",
      "pred-> are you going to do this place ? EOS\n",
      "ans-> are there any cute girls in your class?\n",
      "------------------\n",
      "src-> 自分 で 作り まし た 。\n",
      "\n",
      "pred-> i want to go . EOS\n",
      "ans-> i made it myself.\n",
      "------------------\n",
      "src-> さあ 、 始め ましょ う 。\n",
      "\n",
      "pred-> lets go out . EOS\n",
      "ans-> lets get started.\n",
      "------------------\n",
      "src-> 気 を つけ て ！\n",
      "\n",
      "pred-> be careful . EOS\n",
      "ans-> take care.\n",
      "------------------\n",
      "src-> 彼 が 誰 だ か 知り ませ ん 。\n",
      "\n",
      "pred-> i dont know what he is planning to do . EOS\n",
      "ans-> i dont know who he is.\n",
      "------------------\n",
      "src-> 彼 は 黙っ た まま だっ た 。\n",
      "\n",
      "pred-> he was absent from school . EOS\n",
      "ans-> he remained silent.\n",
      "------------------\n",
      "src-> うそ を つく な 、 正直 で あれ 。\n",
      "\n",
      "pred-> dont tell anybody who says . EOS\n",
      "ans-> dont lie. tell the truth.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for src,pred,target in zip(val_data[src_col],ret,val_data[trg_col]):\n",
    "    print(\"src->\",src)\n",
    "    print()\n",
    "    print(\"pred->\",\" \".join(Langs[\"trg\"].id2word(pred)))\n",
    "    print(\"ans->\",target)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drEeGLeON8Jj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1-LSTM",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
