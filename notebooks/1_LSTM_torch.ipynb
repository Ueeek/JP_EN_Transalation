{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "sys.path.append(\"/Users/ueki/Desktop/work/jp_en_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Seq2Seq_1_torch import EncoderRnn,DecoderRnn\n",
    "from utils.LangEn import LangEn\n",
    "from utils.LangJa import LangJa\n",
    "from utils.preprocess import loadLangs\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"corpus_file\":\"../data/jpn.txt\",\n",
    "    \"en_col\":\"description_en\",\n",
    "    \"jp_col\":\"description_jp\",\n",
    "    \"SOS_token\":1,\n",
    "    \"EOS_token\":0,\n",
    "    \"UNK_token\":2,\n",
    "    \"max_features\":5000,\n",
    "    \"MAX_LENGTH\":20,\n",
    "    \"train_size\":15000,\n",
    "    \"val_size\":100,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":20,\n",
    "    \"maxlen_enc\":20,\n",
    "    \"maxlen_dec\":20,\n",
    "    \"n_hidden\":300,\n",
    "    \"input_dim\":5000,\n",
    "    \"output_dim\":5000,\n",
    "    \"emb_dim\":300,\n",
    "    \"use_enc_emb\":False,\n",
    "    \"use_dec_emb\":False,\n",
    "    \"validation_split\":0.1,\n",
    "    \"trained_param_dir\":\"../trained_models/1_lstm_ja_en_01.hdf5\",\n",
    "    \"translate_length\":25,\n",
    "    \"en_W2V_FILE\" : \"../data/GoogleNews-vectors-negative300.bin.gz\",\n",
    "    \"jp_W2V_FILE\":\"../data/ja_data/ja.bin\",\n",
    "    \"src\":\"en\",\n",
    "    \"trg\":\"jp\",\n",
    "    \"learning_rate\":0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class EncoderRnn(nn.Module):\n",
    "    \"\"\"\n",
    "    encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(EncoderRnn, self).__init__()\n",
    "        self.hidden_size = config[\"n_hidden\"]\n",
    "        self.input_size = config[\"max_features\"]\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.lstm = nn.GRU(\n",
    "            self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class DecoderRnn(nn.Module):\n",
    "    \"\"\"\n",
    "    decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(DecoderRnn, self).__init__()\n",
    "        self.hidden_size = config[\"n_hidden\"]\n",
    "        self.output_size = config[\"max_features\"]\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.lstm = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFjiCn22blbf"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,config):\n",
    "        self.print_every=10\n",
    "        self.plot_every=100\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.encoder = EncoderRnn(config)\n",
    "        self.decoder = DecoderRnn(config)\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self. encoder_optimizer = optim.SGD(self.encoder.parameters(),lr = self.learning_rate)\n",
    "        self.decoder_opimizer = optim.SGD(self.decoder.parameters(),lr=self.learning_rate)\n",
    "        \n",
    "    def train(self,input_tensor,target_tensor):\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        \n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_opimizer.zero_grad()\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "        \n",
    "        #encoder\n",
    "        encoder_outputs = torch.zeros(config[\"MAX_LENGTH\"],config[\"n_hidden\"],device=device)\n",
    "        loss = 0\n",
    "        for ei in range(input_length):\n",
    "            encoder_output,encoder_hidden = self.encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0,0]\n",
    "            \n",
    "        # decoder\n",
    "        decoder_input = torch.tensor([[config[\"SOS_token\"]]],device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        for di in range(target_length):\n",
    "            decoder_output,decoder_hidden = self.decoder(decoder_input,decoder_hidden)\n",
    "            loss += self.criterion(decoder_output,target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "        \n",
    "        # back propagate\n",
    "        loss.backward()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_opimizer.step()\n",
    "        return loss.item() / target_length\n",
    "    \n",
    "    def trainIters(self,src,trg,n_iters):\n",
    "        plot_losses=[]\n",
    "        print_loss_total=0\n",
    "        plot_loss_total=0\n",
    "        \n",
    "        encoder_optimizer = optim.SGD(self.encoder.parameters(),lr = self.learning_rate)\n",
    "        decoder_opimizer = optim.SGD(self.decoder.parameters(),lr=self.learning_rate)\n",
    "        \n",
    "        for iter in range(1,n_iters+1):\n",
    "            input_tensor=src[iter-1]\n",
    "            target_tensor=trg[iter-1]\n",
    "            loss =self.train(input_tensor,target_tensor)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "            if iter %self.print_every==0:\n",
    "                print_loss_avg = print_loss_total/self.print_every\n",
    "                print_loss_total=0\n",
    "                print(\"loss_av->\",print_loss_avg)\n",
    "            \n",
    "            if iter % self.plot_every==0:\n",
    "                plot_loss_avg = plot_loss_total/self.plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "        showPlot(plot_losses)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self,config):\n",
    "        self.translate_length = config[\"translate_length\"]\n",
    "        self.trained_param_dir = config[\"trained_param_dir\"]\n",
    "        self.model,self.encoder,self.decoder = build_model(config,test=True)\n",
    "        self.model.load_weights(self.trained_param_dir)\n",
    "    ## 翻訳文生成\n",
    "    def _translate(self,e_input):\n",
    "        #encode input to vec\n",
    "        #encoder_outputs,state_h_1,state_c_1 = self.encoder.predict(e_input)\n",
    "        #states_values=[state_h_1,state_c_1]\n",
    "        encoder_outputs,*states_values = self.encoder.predict(e_input)\n",
    "        \n",
    "        #first token\n",
    "        target_seq=np.zeros((1,1))\n",
    "        target_seq[0,0] = config[\"SOS_token\"]\n",
    "        \n",
    "        decoded_sentence=[]\n",
    "        for i in range(0,self.translate_length):\n",
    "            #output_tokens,h1,c1 = self.decoder.predict([target_seq]+states_values)\n",
    "            output_tokens,*states_values = self.decoder.predict([target_seq]+states_values)\n",
    "            \n",
    "            sampled_token_index=np.argmax(output_tokens[0,0,:])\n",
    "            if sampled_token_index==config[\"EOS_token\"]:\n",
    "                decoded_sentence.append(config[\"EOS_token\"])\n",
    "                break\n",
    "            else:\n",
    "                target_seq[0,0] = sampled_token_index\n",
    "                #states_values =[h1,c1]\n",
    "                decoded_sentence.append(sampled_token_index)\n",
    "        return decoded_sentence                                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def translate_demo(self,src_data_id_seq):\n",
    "        ret=[]\n",
    "        for src in src_data_id_seq:\n",
    "            id_seq_mat = np.array([src])\n",
    "            pred_id_padded = sequence.pad_sequences(id_seq_mat,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "            pred=self._translate(pred_id_padded)\n",
    "            ret.append(pred)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_en_emb(config):\n",
    "    en_word2vec= KeyedVectors.load_word2vec_format(config[\"en_W2V_FILE\"],binary=True)\n",
    "    en_EMBEDDING_DIM=config[\"emb_dim\"]\n",
    "    #n_word<max_featureの時にerrになるよ\n",
    "    vocabulary_size=min(EN_lang.n_words,config[\"max_features\"])\n",
    "    en_embedding_matrix = np.zeros((vocabulary_size, en_EMBEDDING_DIM))\n",
    "    print(\"voc->\",vocabulary_size)\n",
    "    cnt=0\n",
    "    for word, i in EN_lang.word2index.items():\n",
    "        if   i==0 or i==1 or i ==2:\n",
    "            continue\n",
    "        try:\n",
    "            en_embedding_vector = en_word2vec[word]\n",
    "            en_embedding_matrix[i] = en_embedding_vector\n",
    "        except KeyError:\n",
    "            cnt+=1\n",
    "            en_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),en_EMBEDDING_DIM)\n",
    "    print(\"UNK_rate\",cnt/i)\n",
    "    del en_word2vec\n",
    "    gc.collect()\n",
    "    return en_embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "QA-6hirSN7c3",
    "outputId": "e9b07f89-37e4-4be1-e085-9e7cc53a4a20"
   },
   "outputs": [],
   "source": [
    "def build_jp_emb(config):\n",
    "    jp_word2vec= model = Word2Vec.load(config[\"jp_W2V_FILE\"])\n",
    "    jp_EMBEDDING_DIM=config[\"emb_dim\"]\n",
    "    vocabulary_size=min(JP_lang.n_words,config[\"max_features\"])\n",
    "    jp_embedding_matrix = np.zeros((vocabulary_size, jp_EMBEDDING_DIM))\n",
    "    print(\"voc->\",vocabulary_size)\n",
    "    cnt=0\n",
    "    for word, i in JP_lang.word2index.items():\n",
    "        if   i==0 or i==1 or i ==2:\n",
    "            continue\n",
    "        try:\n",
    "            jp_embedding_vector = jp_word2vec[word]\n",
    "            jp_embedding_matrix[i] = jp_embedding_vector\n",
    "        except KeyError:\n",
    "            cnt+=1\n",
    "            jp_embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25),jp_EMBEDDING_DIM)\n",
    "    print(\"UNK/rate->\",cnt/i)\n",
    "\n",
    "    del jp_word2vec\n",
    "    gc.collect()\n",
    "    return jp_embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h6V9OfqpcQn"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YmVIGLgYpdn2",
    "outputId": "703c3b2f-347a-4377-af52-f1ce4717b447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lines\n"
     ]
    }
   ],
   "source": [
    "data=loadLangs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FCy7THnpdim"
   },
   "outputs": [],
   "source": [
    "val_data = data[config[\"train_size\"]:config[\"train_size\"]+config[\"val_size\"]]\n",
    "data = data[:config[\"train_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsa0heCPpow7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 16:58:22.039391 4477343168 toolwrapper.py:77] stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    }
   ],
   "source": [
    "EN_lang = LangEn(config)\n",
    "JP_lang = LangJa(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWurNSGQpoug"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"en_col\"]]:\n",
    "    EN_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJgN_yKjposQ"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"jp_col\"]]:\n",
    "    JP_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5Tz-dt4YJUu"
   },
   "source": [
    "## input の加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"src\"]==\"jp\":\n",
    "    src_col=config[\"jp_col\"]\n",
    "    trg_col=config[\"en_col\"]\n",
    "    Langs={\"src\":JP_lang,\"trg\":EN_lang}\n",
    "else:\n",
    "    src_col=config[\"en_col\"]\n",
    "    trg_col=config[\"jp_col\"]\n",
    "    Langs={\"trg\":JP_lang,\"src\":EN_lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZkMItuoprY2"
   },
   "outputs": [],
   "source": [
    "input_en = data[src_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6IBzGaKvpYS"
   },
   "outputs": [],
   "source": [
    "input_source_lang=data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
    "input_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x,target=True))\n",
    "output_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNv2-2QGwJOP"
   },
   "outputs": [],
   "source": [
    "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "output_target_padded=sequence.pad_sequences(output_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_src = [torch.tensor(v,dtype=torch.long,device=device).view(-1,1) for v in input_source_padded]\n",
    "input_target = [torch.tensor(v,dtype=torch.long,device=device).view(-1,1) for v in output_target_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_av-> 4.5052435684204095\n",
      "loss_av-> 3.7192385864257806\n",
      "loss_av-> 2.8749882507324225\n",
      "loss_av-> 3.4676425743103025\n",
      "loss_av-> 3.4339290046691895\n",
      "loss_av-> 2.7729095268249515\n",
      "loss_av-> 3.0756567001342776\n",
      "loss_av-> 3.3586873054504394\n",
      "loss_av-> 2.614885807037353\n",
      "loss_av-> 2.904715032577515\n",
      "[3.2727896356582646]\n",
      "loss_av-> 2.697892322540283\n",
      "loss_av-> 3.287667245864868\n",
      "loss_av-> 2.683876523971558\n",
      "loss_av-> 3.4421010971069337\n",
      "loss_av-> 2.8516497802734375\n",
      "loss_av-> 2.673665828704834\n",
      "loss_av-> 2.685142087936401\n",
      "loss_av-> 2.7042793369293214\n",
      "loss_av-> 2.796598463058472\n",
      "loss_av-> 2.1502116107940674\n",
      "[3.2727896356582646, 2.797308429718019]\n",
      "loss_av-> 3.043031692504883\n",
      "loss_av-> 3.055671110153198\n",
      "loss_av-> 2.789596328735352\n",
      "loss_av-> 2.800029773712158\n",
      "loss_av-> 2.8537470531463622\n",
      "loss_av-> 2.5974528789520264\n",
      "loss_av-> 2.3835856103897095\n",
      "loss_av-> 2.9103670310974126\n",
      "loss_av-> 3.4788166999816896\n",
      "loss_av-> 2.6717538452148437\n",
      "[3.2727896356582646, 2.797308429718019, 2.858405202388764]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.trainIters(input_src,input_target,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m8_2NQDMYRrV",
    "outputId": "577b1ea5-a7c7-4601-983f-e29ad73d26ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del trainer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5khAA1aymGoX"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N9v_wwtqu6E"
   },
   "outputs": [],
   "source": [
    "val_data_id = val_data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aA--RWDUHjPB",
    "outputId": "ac683833-7751-43e7-fd89-01a41abff1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15043                        [206, 20, 560, 8, 1643, 5, 0]\n",
       "15044                    [25, 52, 8, 205, 358, 4270, 5, 0]\n",
       "15045        [10, 512, 351, 215, 3569, 32, 27, 2130, 5, 0]\n",
       "15046                       [18, 56, 1740, 397, 765, 5, 0]\n",
       "15047    [111, 44, 753, 65, 1793, 50, 455, 79, 2360, 5, 0]\n",
       "15048                    [175, 1875, 27, 2983, 2363, 5, 0]\n",
       "15049                    [170, 75, 44, 2, 614, 1219, 5, 0]\n",
       "15050             [490, 22, 44, 2, 2, 12, 144, 1109, 5, 0]\n",
       "15051                           [4, 56, 2, 111, 121, 5, 0]\n",
       "15052        [63, 792, 7, 584, 256, 16, 44, 591, 37, 5, 0]\n",
       "Name: description_en, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-7b2993995cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-61e5f3e4c3e7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"translate_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_param_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trained_param_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_param_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m## 翻訳文生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "translator = Translator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = translator.translate_demo(val_data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0w7srpDEx_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src-> theres no need to hurry.\n",
      "\n",
      "pred-> 急が ない と 遅れる よ 。 EOS\n",
      "ans-> 急ぐ 必要 は あり ませ ん 。\n",
      "------------------\n",
      "src-> i want to join your band.\n",
      "\n",
      "pred-> UNK の 方 が UNK さ れ てる よ 。 EOS\n",
      "ans-> あなた の バンド に 入り たい な 。\n",
      "------------------\n",
      "src-> you must keep an eye on the child.\n",
      "\n",
      "pred-> その 本 は UNK に なり たい 。 EOS\n",
      "ans-> その 子 から 目 を 離さ ない よう に し なけれ ば いけ ない 。\n",
      "------------------\n",
      "src-> he is mad about music.\n",
      "\n",
      "pred-> 彼 は 音楽 が 好き で ある 。 EOS\n",
      "ans-> 彼 は 音楽 狂 だ 。\n",
      "------------------\n",
      "src-> with a little more patience she would have succeeded.\n",
      "\n",
      "pred-> 彼女 が そんな こと を し た ので 、 私 は 何 か 知っ て い まし た 。 EOS\n",
      "ans-> もし 彼女 が もう少し 我慢強かっ たら 、 成功 し て い た だろ う に 。\n",
      "------------------\n",
      "src-> they painted the fence green.\n",
      "\n",
      "pred-> 彼ら は UNK で UNK し て いる 。 EOS\n",
      "ans-> 彼ら は フェンス を 緑色 に 塗っ た 。\n",
      "------------------\n",
      "src-> there was a convention last month.\n",
      "\n",
      "pred-> UNK が UNK た 。 EOS\n",
      "ans-> 先月 、 集会 が あっ た 。\n",
      "------------------\n",
      "src-> shes not a fulltime employee of this company.\n",
      "\n",
      "pred-> 彼女 は UNK UNK も 全く 速く UNK 。 EOS\n",
      "ans-> 彼女 は この 会社 の 正社員 で は あり ませ ん 。\n",
      "------------------\n",
      "src-> tom is arguing with mary.\n",
      "\n",
      "pred-> トム は メアリー と UNK し て いる 。 EOS\n",
      "ans-> トム は メアリー と 喧嘩 し て いる 。\n",
      "------------------\n",
      "src-> it looks like today will be a long day.\n",
      "\n",
      "pred-> 雨 が 降っ て いる ので 、 私 は 犬 に 慣れ ます 。 EOS\n",
      "ans-> 今日 は 長い 一 日 に なり そう です 。\n",
      "------------------\n",
      "src-> tom cried all night long.\n",
      "\n",
      "pred-> トム は 一 日 中 泣い て いる 。 EOS\n",
      "ans-> トム は 一 晩 中 泣き明かし た 。\n",
      "------------------\n",
      "src-> tom didnt want it.\n",
      "\n",
      "pred-> トム は それ を する こと が でき ない 。 EOS\n",
      "ans-> トム は 欲しく なかっ た 。\n",
      "------------------\n",
      "src-> i was moved to tears by her speech.\n",
      "\n",
      "pred-> 私 は 彼女 に 会っ た とたん 、 UNK た 。 EOS\n",
      "ans-> 彼女 の スピーチ で 感動 し て 泣い た 。\n",
      "------------------\n",
      "src-> his wife was nowhere to be seen.\n",
      "\n",
      "pred-> 彼 の 部屋 は きちんと UNK て も 、 UNK し た 。 EOS\n",
      "ans-> 彼 の 妻 の 姿 は どこ に も 見え なかっ た 。\n",
      "------------------\n",
      "src-> in october i was in boston.\n",
      "\n",
      "pred-> その 歌 は よく 知っ て いる 。 EOS\n",
      "ans-> 10 月 は ボストン に い た 。\n",
      "------------------\n",
      "src-> i go to any party i am invited to.\n",
      "\n",
      "pred-> 私 が ここ に 来 て から 、 私 は 普通 は 外出 でき ない 。 EOS\n",
      "ans-> 私 は 招待 さ れ た パーティー に は 必ず 出席 する 。\n",
      "------------------\n",
      "src-> which player are you paying the most attention to this year?\n",
      "\n",
      "pred-> 今日 の 午後 は どう やっ て いく の は ？ EOS\n",
      "ans-> 今年 、 注目 し て いる 選手 は 誰 です か 。\n",
      "------------------\n",
      "src-> he earns more money than he can spend.\n",
      "\n",
      "pred-> 彼 は その 知らせ に 驚い た よう な 。 EOS\n",
      "ans-> 彼 は 使い きれ ない ほど の 金 を 稼ぐ 。\n",
      "------------------\n",
      "src-> i intend to try doing everything i can.\n",
      "\n",
      "pred-> 私 たち は 、 あなた が UNK と 思っ て い ます 。 EOS\n",
      "ans-> できる 限り の こと は し て みる つもり だ 。\n",
      "------------------\n",
      "src-> i dont want to tell you the truth.\n",
      "\n",
      "pred-> そんな こと を し て いる と 言う こと に は ない 。 EOS\n",
      "ans-> あなた に は 本当 の こと を 言い たく ない の 。\n",
      "------------------\n",
      "src-> will it hurt a lot?\n",
      "\n",
      "pred-> ひどく 痛い の ？ EOS\n",
      "ans-> かなり 痛む の です か 。\n",
      "------------------\n",
      "src-> i couldnt answer any questions on the test.\n",
      "\n",
      "pred-> もう 二 人 とも 正しい と 思う ん です 。 EOS\n",
      "ans-> テスト で 一 問 も 答え られ なかっ た 。\n",
      "------------------\n",
      "src-> tom talks like an old man.\n",
      "\n",
      "pred-> トム は 携帯 UNK の が 好き だ 。 EOS\n",
      "ans-> トム は 老人 の よう な 話し方 を する 。\n",
      "------------------\n",
      "src-> he likes to read books.\n",
      "\n",
      "pred-> 彼 は 本 を 読む の が 大好き だ 。 EOS\n",
      "ans-> 彼 は 本 を 読む の が 好き だ 。\n",
      "------------------\n",
      "src-> did you mistake the margarine for butter?\n",
      "\n",
      "pred-> あなた は １ ９ ８ ０ 年 の 主要 な 出来事 と 話し て い ます か 。 EOS\n",
      "ans-> マーガリン を バター と 間違え た の ？\n",
      "------------------\n",
      "src-> i thought nothing of it.\n",
      "\n",
      "pred-> それ は 本当 な こと を 聞い た 。 EOS\n",
      "ans-> なんて こと なかっ た 。\n",
      "------------------\n",
      "src-> parallel lines do not intersect each other.\n",
      "\n",
      "pred-> UNK は UNK と UNK する もの が ある 。 EOS\n",
      "ans-> 平行 線 は 交差 し ませ ん 。\n",
      "------------------\n",
      "src-> im actually a university teacher.\n",
      "\n",
      "pred-> 私 は 先生 に 怒ら れ た 。 EOS\n",
      "ans-> 正確 に 言う と 私 は 大学 講師 です 。\n",
      "------------------\n",
      "src-> ten years have passed since he died.\n",
      "\n",
      "pred-> 彼 が UNK に 入っ た 。 EOS\n",
      "ans-> 彼 が 死ん で から 十 年 に なり ます 。\n",
      "------------------\n",
      "src-> money does not always bring happiness.\n",
      "\n",
      "pred-> 多く の 人 が UNK を し て い ない ん です 。 EOS\n",
      "ans-> お金 が 幸福 を もたらす と は 限ら ない 。\n",
      "------------------\n",
      "src-> she was surprised at the news.\n",
      "\n",
      "pred-> 彼女 は その 知らせ に 驚い た 。 EOS\n",
      "ans-> 彼女 は その ニュース を 聞い て 驚い た 。\n",
      "------------------\n",
      "src-> he stabbed me in the back!\n",
      "\n",
      "pred-> 彼 は 私 に １ 時 に 帰っ て き た 。 EOS\n",
      "ans-> やつ は 僕 を 裏切っ た ん だ ！\n",
      "------------------\n",
      "src-> toms planning something special for marys birthday.\n",
      "\n",
      "pred-> トム の 誕生 日 の 名前 を 思い出せ ない 。 EOS\n",
      "ans-> トム は メアリー の 誕生 日 に 何 か 特別 な こと を 計画 し て いる 。\n",
      "------------------\n",
      "src-> he wrote the report.\n",
      "\n",
      "pred-> 彼 は UNK を UNK し た 。 EOS\n",
      "ans-> 彼 は 報告 書 を 作文 し た 。\n",
      "------------------\n",
      "src-> can i change the route?\n",
      "\n",
      "pred-> UNK を UNK て い ます か 。 EOS\n",
      "ans-> 路線 の 変更 は でき ます か 。\n",
      "------------------\n",
      "src-> he is at his desk.\n",
      "\n",
      "pred-> 彼 は その 本 を 読ん で いる 。 EOS\n",
      "ans-> 彼 は 机 に 向かっ て いる 。\n",
      "------------------\n",
      "src-> war began five years later.\n",
      "\n",
      "pred-> 嵐 は 作物 に 多大 な 影響 を 与え た 。 EOS\n",
      "ans-> 5 年 後 に 戦争 が 始まっ た 。\n",
      "------------------\n",
      "src-> they formed themselves into a circle.\n",
      "\n",
      "pred-> 彼ら は UNK UNK だっ た 。 EOS\n",
      "ans-> 彼ら は 輪 に なっ た 。\n",
      "------------------\n",
      "src-> i used to play tennis in high school.\n",
      "\n",
      "pred-> 私 は いつも 学校 に 遅れる かも しれ ない 。 EOS\n",
      "ans-> 高校 時代 は よく テニス を し た もの です 。\n",
      "------------------\n",
      "src-> it was such a shock.\n",
      "\n",
      "pred-> それ が UNK だっ た 。 EOS\n",
      "ans-> それ は たいへん な ショック でし た 。\n",
      "------------------\n",
      "src-> whose umbrella is this?\n",
      "\n",
      "pred-> これ 誰 の ？ EOS\n",
      "ans-> これ 誰 の 傘 ？\n",
      "------------------\n",
      "src-> show me how.\n",
      "\n",
      "pred-> あなた の UNK を 見 て くれ ます 。 EOS\n",
      "ans-> どう やっ て やる の か 教え て 。\n",
      "------------------\n",
      "src-> did anybody get injured?\n",
      "\n",
      "pred-> 誰 か 怪我 し た ？ EOS\n",
      "ans-> 誰 か 怪我 し た ？\n",
      "------------------\n",
      "src-> if you calculate the electric field using this equation the result comes out like the following.\n",
      "\n",
      "pred-> 「 私 は 今日 の 午後 、 被災 し て 初めて だ から 、 彼ら が UNK まし た 。 EOS\n",
      "ans-> この 式 によって 電場 を 計算 し て やる と 、 結果 は 次 の よう に なる 。\n",
      "------------------\n",
      "src-> the travelers came from many lands.\n",
      "\n",
      "pred-> UNK に UNK が 鳴っ た 。 EOS\n",
      "ans-> 旅行 者 達 は いろいろ な 国 から やって来 た 。\n",
      "------------------\n",
      "src-> communications broke down.\n",
      "\n",
      "pred-> UNK を UNK 。 EOS\n",
      "ans-> 通信 手段 が 機能 し なく なっ た 。\n",
      "------------------\n",
      "src-> the sunny side of the hill is full of deciduous trees.\n",
      "\n",
      "pred-> １ ９ ９ ８ 年 前 の UNK は １ 日 に UNK れ て いる 。 EOS\n",
      "ans-> 丘 の 日 が 当っ て いる 部分 は 落葉樹 で いっぱい だ 。\n",
      "------------------\n",
      "src-> can you tell me how to get to the station?\n",
      "\n",
      "pred-> 駅 まで の 行き 方 を 教え て い た だけ ませ ん か 。 EOS\n",
      "ans-> 駅 へ どう 行っ たら 良い か を 教え て もらえ ませ ん か 。\n",
      "------------------\n",
      "src-> the old man was loved by everyone.\n",
      "\n",
      "pred-> その 知らせ に その 知らせ は UNK た 。 EOS\n",
      "ans-> その 老人 は 皆 に 愛さ れ て い た 。\n",
      "------------------\n",
      "src-> he pinched and scraped for many years to save money.\n",
      "\n",
      "pred-> 彼 は UNK に UNK を UNK う と 努力 し て いる 。 EOS\n",
      "ans-> 彼 は 金 を ためる ため 何 年間 も けちけち 倹約 し た 。\n",
      "------------------\n",
      "src-> the brain needs a continuous supply of blood.\n",
      "\n",
      "pred-> UNK は UNK やすい もの だ と 思う 。 EOS\n",
      "ans-> 小脳 は 血液 の 不断 の 供給 を 必要 と する 。\n",
      "------------------\n",
      "src-> his remark was really out of line.\n",
      "\n",
      "pred-> 彼 の UNK は UNK だ から 、 UNK 。 EOS\n",
      "ans-> 彼 の 意見 は 本当に 場違い だっ た 。\n",
      "------------------\n",
      "src-> im in trouble now.\n",
      "\n",
      "pred-> もう 一 回 やっ て み なさい 。 EOS\n",
      "ans-> 今 困っ て いる ん だ 。\n",
      "------------------\n",
      "src-> nobody knows whats going to happen.\n",
      "\n",
      "pred-> 誰 に も 言わ ない と 誓い ます か 。 EOS\n",
      "ans-> これから 何 が 起こる の か 、 誰 に も わから ない 。\n",
      "------------------\n",
      "src-> she has been watching television for three hours.\n",
      "\n",
      "pred-> 彼女 は 彼 に 会う の は 、 テレビ で 見 て い ます 。 EOS\n",
      "ans-> 彼女 は ３ 時間 テレビ を 見 続け て いる 。\n",
      "------------------\n",
      "src-> may i eat this bread?\n",
      "\n",
      "pred-> これ 、 UNK ない ん です か ？ EOS\n",
      "ans-> この パン 食べ て も いい ？\n",
      "------------------\n",
      "src-> see you.\n",
      "\n",
      "pred-> あなた に 会い まし た 。 EOS\n",
      "ans-> じゃ 、 また ねっ ！\n",
      "------------------\n",
      "src-> how long have you been looking for it?\n",
      "\n",
      "pred-> あなた は どこ に 住ん で いる の ？ EOS\n",
      "ans-> いつ から それ を お 探し です か 。\n",
      "------------------\n",
      "src-> the moon has set.\n",
      "\n",
      "pred-> UNK が 出 て い た 。 EOS\n",
      "ans-> 月 が 沈ん だ 。\n",
      "------------------\n",
      "src-> he looked into her eyes and suddenly went away.\n",
      "\n",
      "pred-> 彼女 は 目 を UNK て い た 。 EOS\n",
      "ans-> 彼 は 彼女 の 目 を 覗き 込む と 、 突然 立ち去っ た 。\n",
      "------------------\n",
      "src-> his grandmother looks healthy.\n",
      "\n",
      "pred-> 彼 の UNK は 好き で は あり ませ ん 。 EOS\n",
      "ans-> 彼 の おばあさん は 元気 そう です 。\n",
      "------------------\n",
      "src-> why do you love me?\n",
      "\n",
      "pred-> どうして あなた は 何 が 起こっ た ん です か ？ EOS\n",
      "ans-> なんで 私 の こと 好き な の ？\n",
      "------------------\n",
      "src-> i held on to the rope tightly so i wouldnt fall.\n",
      "\n",
      "pred-> 私 が 一 晩 中 踊る つもり だ と 言っ た 。 EOS\n",
      "ans-> 落ち ない よう に ロープ を 握りしめ た 。\n",
      "------------------\n",
      "src-> christmas is coming soon.\n",
      "\n",
      "pred-> もうすぐ クリスマス だ ね 。 EOS\n",
      "ans-> クリスマス が 近く なっ て き た 。\n",
      "------------------\n",
      "src-> we hurried to the train station.\n",
      "\n",
      "pred-> 私 たち が ここ に 駅 に 着い た 。 EOS\n",
      "ans-> 私 達 は 駅 へ 急い だ 。\n",
      "------------------\n",
      "src-> i have a good idea.\n",
      "\n",
      "pred-> いい 人 です 。 EOS\n",
      "ans-> いい 考え が あり ます 。\n",
      "------------------\n",
      "src-> theres nothing harder than a diamond.\n",
      "\n",
      "pred-> UNK は 、 UNK は まだ 生き て いる 。 EOS\n",
      "ans-> ダイヤモンド ほど 硬い もの は ない 。\n",
      "------------------\n",
      "src-> does it hurt a lot?\n",
      "\n",
      "pred-> ひどく 痛い の ？ EOS\n",
      "ans-> とっても 痛む ？\n",
      "------------------\n",
      "src-> thanks to his recommendation i was able to get a teaching job at a college in tokyo.\n",
      "\n",
      "pred-> 昔 の 友達 に 似 て い た が 、 私 が 大学 に 行き たい の を 見 て い た 。 EOS\n",
      "ans-> 彼 の 推薦 の おかげ で 、 私 は 東京 の 大学 で 教鞭 を とる こと が 出来 た 。\n",
      "------------------\n",
      "src-> theyre studying french and web design.\n",
      "\n",
      "pred-> 彼ら に は フランス語 が 話せる 人 を いる 。 EOS\n",
      "ans-> フランス語 と ウェブ・デザイン を 勉強 し て い ます 。\n",
      "------------------\n",
      "src-> five years have gone by since my father died.\n",
      "\n",
      "pred-> 父 が 私 の 仕事 を １ ０ ドル かかっ た 。 EOS\n",
      "ans-> 父 が 死ん で から 五 年 が 過ぎ た 。\n",
      "------------------\n",
      "src-> please write to me once in a while.\n",
      "\n",
      "pred-> 手紙 を 書い て ください 。 EOS\n",
      "ans-> たま に は 手紙 を 書い て ください 。\n",
      "------------------\n",
      "src-> mother has just gone shopping.\n",
      "\n",
      "pred-> 母 は 先週 大阪 を 行っ た 。 EOS\n",
      "ans-> 母 は ちょうど 買い物 に 出かけ た ところ です 。\n",
      "------------------\n",
      "src-> he was acquainted with everybody in town.\n",
      "\n",
      "pred-> 彼 は UNK に UNK を し た 。 EOS\n",
      "ans-> 彼 は 町 の 人 みんな と 付き合い が あっ た 。\n",
      "------------------\n",
      "src-> this bus can hold fifty people.\n",
      "\n",
      "pred-> この 歌 が 起こる の を 歌っ て いる 。 EOS\n",
      "ans-> この バス は 50 人 乗り です 。\n",
      "------------------\n",
      "src-> he loves traveling.\n",
      "\n",
      "pred-> 彼 は 目的 を 達成 し た 。 EOS\n",
      "ans-> 彼 は 旅行 が 大好き だ 。\n",
      "------------------\n",
      "src-> i should head out.\n",
      "\n",
      "pred-> UNK を し ます 。 EOS\n",
      "ans-> 出発 し なく て は いけ ない 。\n",
      "------------------\n",
      "src-> im afraid this data isnt reliable.\n",
      "\n",
      "pred-> 今日 の UNK は どこ に ある か わから ない 。 EOS\n",
      "ans-> この データ は 信用 でき ない と 思う 。\n",
      "------------------\n",
      "src-> a strange man was walking back and forth on the pavement.\n",
      "\n",
      "pred-> 警察 は その 事故 を UNK に 行っ た 。 EOS\n",
      "ans-> 見知らぬ 男 が 歩道 を 行っ たり 来 たり し て い た 。\n",
      "------------------\n",
      "src-> you have made all my dreams come true.\n",
      "\n",
      "pred-> あなた の UNK は 、 UNK に UNK て いる 。 EOS\n",
      "ans-> あなた は 私 の 夢 を 、 残らず 実現 さ せ て くれ た 。\n",
      "------------------\n",
      "src-> he lives in a large house.\n",
      "\n",
      "pred-> 彼 は 家 に い た ところ を UNK た 。 EOS\n",
      "ans-> 彼 は 広い 家 に 住ん で いる 。\n",
      "------------------\n",
      "src-> excuse me but could you lend me a pen?\n",
      "\n",
      "pred-> すみません が 、 ここ を UNK たい の です が 、 いかが です か 。 EOS\n",
      "ans-> すみません 、 ペン を 貸し て い た だけ ませ ん か ？\n",
      "------------------\n",
      "src-> were pretty pleased with that.\n",
      "\n",
      "pred-> 私 の UNK 、 UNK が 出 て いる 。 EOS\n",
      "ans-> 私 たち は それ で とても 満足 し て い ます 。\n",
      "------------------\n",
      "src-> stand still!\n",
      "\n",
      "pred-> 頭 が 痛い 。 EOS\n",
      "ans-> じっと し て ！\n",
      "------------------\n",
      "src-> could you please pass me the pepper?\n",
      "\n",
      "pred-> すみません が 胡椒 を とっ て 下さい ませ ん か 。 EOS\n",
      "ans-> コショウ を 取っ て もらえ ませ ん か 。\n",
      "------------------\n",
      "src-> tom and mary were dancing to the music.\n",
      "\n",
      "pred-> トム と メアリー は 二 人 とも 家 に いる 。 EOS\n",
      "ans-> トム と メアリー は 音楽 に 合わせ て 踊っ て い た 。\n",
      "------------------\n",
      "src-> nobody understands me.\n",
      "\n",
      "pred-> 誰 も い なかっ た 。 EOS\n",
      "ans-> 誰 も 私 の こと を 分かっ て くれ ない 。\n",
      "------------------\n",
      "src-> i dont know how to spell the word.\n",
      "\n",
      "pred-> 私 は あなた の UNK に は 、 何 が 起き て い ない の か 。 EOS\n",
      "ans-> その 単語 の スペル が わかり ませ ん 。\n",
      "------------------\n",
      "src-> i get the point.\n",
      "\n",
      "pred-> UNK は UNK だ 。 EOS\n",
      "ans-> 了解 し まし た 。\n",
      "------------------\n",
      "src-> he glanced at his watch.\n",
      "\n",
      "pred-> 彼 は UNK を UNK た 。 EOS\n",
      "ans-> 彼 は 時計 を チラッ と 見 た 。\n",
      "------------------\n",
      "src-> i cant stand him.\n",
      "\n",
      "pred-> 私 は 彼 に は 我慢 でき ない 。 EOS\n",
      "ans-> 私 は 彼 に がまん でき ない 。\n",
      "------------------\n",
      "src-> im sure i saw her two years ago.\n",
      "\n",
      "pred-> 私 は 彼女 の UNK に ぴったり UNK て い た 。 EOS\n",
      "ans-> 絶対 彼女 と 2 年 前 に 会っ てる と 思う 。\n",
      "------------------\n",
      "src-> he has an eye for art.\n",
      "\n",
      "pred-> 彼 は 仕事 を する 。 EOS\n",
      "ans-> 彼 は 絵 を 見る 目 が ある 。\n",
      "------------------\n",
      "src-> are there any cute girls in your class?\n",
      "\n",
      "pred-> どういう UNK だ よ ね ？ EOS\n",
      "ans-> クラス に かわいい 子 いる ？\n",
      "------------------\n",
      "src-> i made it myself.\n",
      "\n",
      "pred-> 私 は トム を 信じ て い ます 。 EOS\n",
      "ans-> 自分 で 作り まし た 。\n",
      "------------------\n",
      "src-> lets get started.\n",
      "\n",
      "pred-> さあ 、 UNK 。 EOS\n",
      "ans-> さあ 、 始め ましょ う 。\n",
      "------------------\n",
      "src-> take care.\n",
      "\n",
      "pred-> 気 を 付け て ね 。 EOS\n",
      "ans-> 気 を つけ て ！\n",
      "------------------\n",
      "src-> i dont know who he is.\n",
      "\n",
      "pred-> 彼 が 私 に は それ は 何 か する と 言っ た 。 EOS\n",
      "ans-> 彼 が 誰 だ か 知り ませ ん 。\n",
      "------------------\n",
      "src-> he remained silent.\n",
      "\n",
      "pred-> 彼 は 銀行 に 勤め て いる 。 EOS\n",
      "ans-> 彼 は 黙っ た まま だっ た 。\n",
      "------------------\n",
      "src-> dont lie. tell the truth.\n",
      "\n",
      "pred-> その こと について は 何 か 知っ て い ます 。 EOS\n",
      "ans-> うそ を つく な 、 正直 で あれ 。\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for src,pred,target in zip(val_data[src_col],ret,val_data[trg_col]):\n",
    "    print(\"src->\",src)\n",
    "    print()\n",
    "    print(\"pred->\",\" \".join(Langs[\"trg\"].id2word(pred)))\n",
    "    print(\"ans->\",target)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drEeGLeON8Jj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1-LSTM",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
