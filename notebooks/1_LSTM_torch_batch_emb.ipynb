{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_LSTM_torch_batch_emb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkAJwAxM61Ut",
        "colab_type": "code",
        "outputId": "72340e13-d7d1-4719-eca0-f27b92167d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZLcF8-v7zXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install mosestokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm94dewA74Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# colab　にmecabを入れる\n",
        "#!apt install aptitude\n",
        "#!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "#!pip install mecab-python3==0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNkYPfbD6zdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import gc\n",
        "import os\n",
        "base_dir = \"drive/My Drive/jp_en_translation/\".replace(\"/\",os.sep)\n",
        "emb_dir = \"drive/My Drive/util_data/\".replace(\"/\",os.sep)\n",
        "sys.path.append(\"/Users/ueki/Desktop/work/jp_en_translation\")\n",
        "sys.path.append(\"/Users/ueki/Desktop/JP_EN_Transalation\")\n",
        "sys.path.append(base_dir)\n",
        "sys.path.append(\"drive/My Drive/jp_en_translation\".replace(\"/\",os.sep))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL9b7aR_6zdn",
        "colab_type": "code",
        "outputId": "dea47b9c-6e53-4272-bfbc-f95c765da77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from models.Seq2Seq_emb import Seq2Seq\n",
        "from utils.LangEn import LangEn\n",
        "from utils.LangJa import LangJa\n",
        "from utils.build_emb import build_en_emb,build_jp_emb\n",
        "from utils.preprocess import loadLangs\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import sequence\n",
        "import torch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "rIjCxA-n6zdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config={\n",
        "    \"corpus_file\":base_dir+\"data/jpn.txt\",\n",
        "    \"en_col\":\"description_en\",\n",
        "    \"jp_col\":\"description_jp\",\n",
        "    \"SOS_token\":1,\n",
        "    \"EOS_token\":2,\n",
        "    \"UNK_token\":0,\n",
        "    \"max_features\":8000,\n",
        "    \"MAX_LENGTH\":20,\n",
        "    \"train_size\":15000,\n",
        "    \"val_size\":100,\n",
        "    \"batch_size\":128,\n",
        "    \"epochs\":300,\n",
        "    \"maxlen_enc\":20,\n",
        "    \"maxlen_dec\":20,\n",
        "    \"n_hidden\":300,\n",
        "    \"input_dim\":5000,\n",
        "    \"jp_voc\":8000,\n",
        "    \"en_voc\":5000,\n",
        "    \"output_dim\":8000,\n",
        "    \"emb_dim\":300,\n",
        "    \"use_enc_emb\":False,\n",
        "    \"use_dec_emb\":False,\n",
        "    \"validation_split\":0.1,\n",
        "    \"trained_param_dir\":base_dir+\"trained_models/1_lstm_ja_en_01.hdf5\",\n",
        "    \"translate_length\":25,\n",
        "    \"en_W2V_FILE\" : emb_dir+\"GoogleNews-vectors-negative300.bin.gz\",\n",
        "    \"jp_W2V_FILE\":emb_dir+\"ja_data/ja.bin\",\n",
        "    \"src\":\"en\",\n",
        "    \"trg\":\"jp\",\n",
        "    \"learning_rate\":0.01,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5h6V9OfqpcQn"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YmVIGLgYpdn2",
        "outputId": "5dd76428-a70f-477c-b6c4-4ab2ca992aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data=loadLangs(config)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_FCy7THnpdim",
        "colab": {}
      },
      "source": [
        "val_data = data[config[\"train_size\"]:config[\"train_size\"]+config[\"val_size\"]]\n",
        "data = data[:config[\"train_size\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fsa0heCPpow7",
        "colab": {}
      },
      "source": [
        "EN_lang = LangEn(config)\n",
        "JP_lang = LangJa(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nWurNSGQpoug",
        "colab": {}
      },
      "source": [
        "for s in data[config[\"en_col\"]]:\n",
        "    EN_lang.addSentence(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJgN_yKjposQ",
        "colab": {}
      },
      "source": [
        "for s in data[config[\"jp_col\"]]:\n",
        "    JP_lang.addSentence(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o5Tz-dt4YJUu"
      },
      "source": [
        "## input の加工"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aULbo-pO6zd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config[\"src\"]==\"jp\":\n",
        "    src_col=config[\"jp_col\"]\n",
        "    trg_col=config[\"en_col\"]\n",
        "    Langs={\"src\":JP_lang,\"trg\":EN_lang}\n",
        "else:\n",
        "    src_col=config[\"en_col\"]\n",
        "    trg_col=config[\"jp_col\"]\n",
        "    Langs={\"trg\":JP_lang,\"src\":EN_lang}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZkMItuoprY2",
        "colab": {}
      },
      "source": [
        "input_en = data[src_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u6IBzGaKvpYS",
        "colab": {}
      },
      "source": [
        "input_source_lang=data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
        "input_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kNv2-2QGwJOP",
        "colab": {}
      },
      "source": [
        "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
        "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn2AIUUrXSvy",
        "colab_type": "code",
        "outputId": "9bea2772-a86b-493d-8b72-4de34d73ba6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_source_padded[10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([50, 56, 57, 42, 58, 59, 60, 27, 61,  5,  2,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3hSswVMXUdk",
        "colab_type": "code",
        "outputId": "9269f3d6-61c7-4c1f-9768-2302d76b291e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_target_padded[10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([31, 22, 62, 39, 26, 63, 64,  9, 65, 11, 66,  5,  2,  0,  0,  0,  0,\n",
              "        0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQF1eCts97rK",
        "colab_type": "code",
        "outputId": "c9ca8660-29b1-42ea-d5b8-4c0b659b24df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKk9M26LiLLz",
        "colab_type": "text"
      },
      "source": [
        "## create embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IvBxgqiKRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a9b95883-4b47-4820-c156-5aeed7775918"
      },
      "source": [
        "en_emb = build_en_emb(config,EN_lang.word2index)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "voc-> 5000\n",
            "UNK_rate 0.03740748149629926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPSbCDH-iv3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0292979c-2ef4-4e84-c02b-2fd1ad4abdcb"
      },
      "source": [
        "ja_emb = build_jp_emb(config,JP_lang.word2index)\n",
        "ja_emb.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "voc-> 8000\n",
            "UNK/rate-> 0.6004500562570322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NicIF0E2klcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config[\"src\"]==\"en\":\n",
        "    emb={\"src_emb\":en_emb,\"trg_emb\":ja_emb}\n",
        "else:\n",
        "    emb={\"src_emb\":ja_emb,\"trg_emb\":en_emb}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp4HUYWjyo_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdb195e1-d48d-4ea1-d7c1-fc3d9ef724c4"
      },
      "source": [
        "print(\"enc->\",emb[\"trg_emb\"].shape)\n",
        "print(\"dec->\",emb[\"src_emb\"].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enc-> (8000, 300)\n",
            "dec-> (5000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FJkygex6zeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ec510148-0b51-4420-f389-591cbb10bb8f"
      },
      "source": [
        "trainer = Seq2Seq(config,enc_emb=emb[\"src_emb\"],dec_emb=emb[\"trg_emb\"])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb torch.Size([5000, 300])\n",
            "int-> 5000\n",
            "hid-> 300\n",
            "emb torch.Size([8000, 300])\n",
            "int-> 8000\n",
            "hid-> 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY739NcJ6zeF",
        "colab_type": "code",
        "outputId": "29d0378f-edde-40ef-b21a-e87b823961b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "trainer.trainIters(input_source_padded,input_target_padded)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch1 start\n",
            "loss_av in eopch0=> 44.225765724182125\n",
            "time-> 438.4244737625122\n",
            "epoch2 start\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c8f5b325c81e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_source_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_target_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/jp_en_translation/models/Seq2Seq_emb.py\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/jp_en_translation/models/Seq2Seq_emb.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_tensor, target_tensor)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# print(\"loss->\", type(loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# back propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5khAA1aymGoX"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9N9v_wwtqu6E",
        "colab": {}
      },
      "source": [
        "val_data_id = val_data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6oVdzEbRPTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1NbxAp6zeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ret=[]\n",
        "for s in val_data_id:\n",
        "    ret.append(trainer.translate(s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L0w7srpDEx_s",
        "colab": {}
      },
      "source": [
        "for src,pred,target in zip(val_data[src_col],ret,val_data[trg_col]):\n",
        "    print(\"src->\",src)\n",
        "    print()\n",
        "    print(\"pred->\",\" \".join(Langs[\"trg\"].id2word(pred)))\n",
        "    print(\"ans->\",target)\n",
        "    print(\"------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hqhVW7b6zeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}