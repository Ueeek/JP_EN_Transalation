{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hkAJwAxM61Ut",
    "outputId": "72340e13-d7d1-4719-eca0-f27b92167d26"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZLcF8-v7zXJ"
   },
   "outputs": [],
   "source": [
    "#! pip install mosestokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bm94dewA74Y_"
   },
   "outputs": [],
   "source": [
    "# colab　にmecabを入れる\n",
    "#!apt install aptitude\n",
    "#!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
    "#!pip install mecab-python3==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNkYPfbD6zdj"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "#base_dir = \"drive/My Drive/jp_en_translation/\".replace(\"/\",os.sep)\n",
    "base_dir = \"../\"\n",
    "emb_dir = \"drive/My Drive/util_data/\".replace(\"/\",os.sep)\n",
    "sys.path.append(\"/Users/ueki/Desktop/work/jp_en_translation\")\n",
    "sys.path.append(\"/Users/ueki/Desktop/JP_EN_Transalation\")\n",
    "sys.path.append(base_dir)\n",
    "sys.path.append(\"drive/My Drive/jp_en_translation\".replace(\"/\",os.sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nL9b7aR_6zdn",
    "outputId": "dea47b9c-6e53-4272-bfbc-f95c765da77f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.Seq2Seq_attention import Seq2Seq\n",
    "#from models.Seq2Seq_batch_bidir import Seq2Seq\n",
    "from utils.LangEn import LangEn\n",
    "from utils.LangJa import LangJa\n",
    "from utils.build_emb import build_en_emb,build_jp_emb\n",
    "from utils.preprocess import loadLangs\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "rIjCxA-n6zdq"
   },
   "outputs": [],
   "source": [
    "config={\n",
    "    \"corpus_file\":base_dir+\"data/jpn.txt\",\n",
    "    \"en_col\":\"description_en\",\n",
    "    \"jp_col\":\"description_jp\",\n",
    "    \"SOS_token\":1,\n",
    "    \"EOS_token\":2,\n",
    "    \"UNK_token\":0,\n",
    "    \"max_features\":8000,\n",
    "    \"MAX_LENGTH\":20,\n",
    "    \"train_size\":1000,\n",
    "    \"val_size\":100,\n",
    "    \"batch_size\":1024,\n",
    "    \"epochs\":300,\n",
    "    \"maxlen_enc\":20,\n",
    "    \"maxlen_dec\":20,\n",
    "    \"n_hidden\":300,\n",
    "    \"input_dim\":5000,\n",
    "    \"jp_voc\":8000,\n",
    "    \"en_voc\":5000,\n",
    "    \"output_dim\":8000,\n",
    "    \"emb_dim\":300,\n",
    "    \"use_enc_emb\":False,\n",
    "    \"use_dec_emb\":False,\n",
    "    \"validation_split\":0.1,\n",
    "    \"trained_param_dir\":base_dir+\"trained_models/1_lstm_ja_en_01.hdf5\",\n",
    "    \"translate_length\":25,\n",
    "    \"en_W2V_FILE\" : emb_dir+\"GoogleNews-vectors-negative300.bin.gz\",\n",
    "    \"jp_W2V_FILE\":emb_dir+\"ja_data/ja.bin\",\n",
    "    \"src\":\"en\",\n",
    "    \"trg\":\"jp\",\n",
    "    \"learning_rate\":0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h6V9OfqpcQn"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YmVIGLgYpdn2",
    "outputId": "5dd76428-a70f-477c-b6c4-4ab2ca992aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lines\n"
     ]
    }
   ],
   "source": [
    "data=loadLangs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FCy7THnpdim"
   },
   "outputs": [],
   "source": [
    "val_data = data[config[\"train_size\"]:config[\"train_size\"]+config[\"val_size\"]]\n",
    "data = data[:config[\"train_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsa0heCPpow7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 16:35:19.764319 4385285568 toolwrapper.py:77] stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    }
   ],
   "source": [
    "EN_lang = LangEn(config)\n",
    "JP_lang = LangJa(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWurNSGQpoug"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"en_col\"]]:\n",
    "    EN_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJgN_yKjposQ"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"jp_col\"]]:\n",
    "    JP_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5Tz-dt4YJUu"
   },
   "source": [
    "## input の加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aULbo-pO6zd7"
   },
   "outputs": [],
   "source": [
    "if config[\"src\"]==\"jp\":\n",
    "    src_col=config[\"jp_col\"]\n",
    "    trg_col=config[\"en_col\"]\n",
    "    Langs={\"src\":JP_lang,\"trg\":EN_lang}\n",
    "else:\n",
    "    src_col=config[\"en_col\"]\n",
    "    trg_col=config[\"jp_col\"]\n",
    "    Langs={\"trg\":JP_lang,\"src\":EN_lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZkMItuoprY2"
   },
   "outputs": [],
   "source": [
    "input_en = data[src_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6IBzGaKvpYS"
   },
   "outputs": [],
   "source": [
    "input_source_lang=data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
    "input_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNv2-2QGwJOP"
   },
   "outputs": [],
   "source": [
    "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Rn2AIUUrXSvy",
    "outputId": "9bea2772-a86b-493d-8b72-4de34d73ba6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51, 57, 58, 43, 59, 60, 61, 28, 62,  6,  2,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_source_padded[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "N3hSswVMXUdk",
    "outputId": "9269f3d6-61c7-4c1f-9768-2302d76b291e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 23, 63, 40, 27, 64, 65, 10, 66, 12, 67,  6,  2,  0,  0,  0,  0,\n",
       "        0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_target_padded[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TQF1eCts97rK",
    "outputId": "c9ca8660-29b1-42ea-d5b8-4c0b659b24df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKk9M26LiLLz"
   },
   "source": [
    "## create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "h_IvBxgqiKRQ",
    "outputId": "a9b95883-4b47-4820-c156-5aeed7775918"
   },
   "outputs": [],
   "source": [
    "#en_emb = build_en_emb(config,EN_lang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "mPSbCDH-iv3T",
    "outputId": "0292979c-2ef4-4e84-c02b-2fd1ad4abdcb"
   },
   "outputs": [],
   "source": [
    "#ja_emb = build_jp_emb(config,JP_lang.word2index)\n",
    "#ja_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NicIF0E2klcw"
   },
   "outputs": [],
   "source": [
    "#if config[\"src\"]==\"en\":\n",
    " #   emb={\"src_emb\":en_emb,\"trg_emb\":ja_emb}\n",
    "#else:\n",
    "  #  emb={\"src_emb\":ja_emb,\"trg_emb\":en_emb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2FJkygex6zeD",
    "outputId": "ec510148-0b51-4420-f389-591cbb10bb8f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e7f477414d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src_emb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trg_emb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#trainer = Seq2Seq(config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Seq2Seq(config,enc_emb=emb[\"src_emb\"],dec_emb=emb[\"trg_emb\"])\n",
    "#trainer = Seq2Seq(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "EY739NcJ6zeF",
    "outputId": "29d0378f-edde-40ef-b21a-e87b823961b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 start\n",
      "loss_av in eopch0=> 0.5095064163208007\n",
      "time-> 26.640124082565308\n",
      "epoch2 start\n",
      "epoch3 start\n",
      "epoch4 start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c8f5b325c81e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_source_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_target_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/work/jp_en_translation/models/Seq2Seq_attention.py\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/jp_en_translation/models/Seq2Seq_attention.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_tensor, target_tensor)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# back propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_opimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.trainIters(input_source_padded,input_target_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5khAA1aymGoX"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N9v_wwtqu6E"
   },
   "outputs": [],
   "source": [
    "val_data_id = val_data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6oVdzEbRPTu"
   },
   "outputs": [],
   "source": [
    "val_data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_1NbxAp6zeK"
   },
   "outputs": [],
   "source": [
    "ret=[]\n",
    "for s in val_data_id:\n",
    "    ret.append(trainer.translate(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0w7srpDEx_s"
   },
   "outputs": [],
   "source": [
    "for src,pred,target in zip(val_data[src_col],ret,val_data[trg_col]):\n",
    "    print(\"src->\",src)\n",
    "    print()\n",
    "    print(\"pred->\",\" \".join(Langs[\"trg\"].id2word(pred)))\n",
    "    print(\"ans->\",target)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hqhVW7b6zeN"
   },
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_LSTM_torch_batch_emb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
