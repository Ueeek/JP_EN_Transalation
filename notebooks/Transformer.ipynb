{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNkYPfbD6zdj"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "#base_dir = \"drive/My Drive/jp_en_translation/\".replace(\"/\",os.sep)\n",
    "base_dir = \"../\"\n",
    "emb_dir = \"drive/My Drive/util_data/\".replace(\"/\",os.sep)\n",
    "sys.path.append(\"/Users/ueki/Desktop/work/jp_en_translation\")\n",
    "sys.path.append(\"/Users/ueki/Desktop/JP_EN_Transalation\")\n",
    "sys.path.append(base_dir)\n",
    "sys.path.append(\"drive/My Drive/jp_en_translation\".replace(\"/\",os.sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nL9b7aR_6zdn",
    "outputId": "8913662d-ea92-4923-c504-66b2560d377f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.Transformer import Model\n",
    "from utils.LangEn import LangEn\n",
    "from utils.LangJa import LangJa\n",
    "from utils.build_emb import build_en_emb,build_jp_emb\n",
    "from utils.preprocess import loadLangs\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "rIjCxA-n6zdq"
   },
   "outputs": [],
   "source": [
    "config={\n",
    "    \"corpus_file\":base_dir+\"data/jpn.txt\",\n",
    "    \"en_col\":\"description_en\",\n",
    "    \"jp_col\":\"description_jp\",\n",
    "    \"mask_token\":0,\n",
    "    \"SOS_token\":1,\n",
    "    \"EOS_token\":2,\n",
    "    \"UNK_token\":3,\n",
    "    \"max_features\":8000,\n",
    "    \"MAX_LENGTH\":20,\n",
    "    \"train_size\":15000,\n",
    "    \"val_size\":300,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":1,\n",
    "    \"maxlen_enc\":20,\n",
    "    \"maxlen_dec\":20,\n",
    "    \"n_hidden\":500,\n",
    "    \"input_dim\":5000,\n",
    "    \"jp_voc\":8000,\n",
    "    \"en_voc\":5000,\n",
    "    \"output_dim\":8000,\n",
    "    \"emb_dim\":300,\n",
    "    \"validation_split\":0.01,\n",
    "    \"trained_param_dir\":base_dir+\"trained_models/1_lstm_ja_en_01.hdf5\",\n",
    "    \"translate_length\":20,\n",
    "    \"en_W2V_FILE\" : emb_dir+\"GoogleNews-vectors-negative300.bin.gz\",\n",
    "    \"jp_W2V_FILE\":emb_dir+\"ja_data/ja.bin\",\n",
    "    \"src\":\"en\",\n",
    "    \"trg\":\"jp\",\n",
    "    \"learning_rate\":0.001,\n",
    "    \"n_heads\":5,\n",
    "    \"n_layer\":4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h6V9OfqpcQn"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YmVIGLgYpdn2",
    "outputId": "dd8e83e5-331f-4138-d331-377977f18717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lines\n"
     ]
    }
   ],
   "source": [
    "data=loadLangs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FCy7THnpdim"
   },
   "outputs": [],
   "source": [
    "val_data = data[config[\"train_size\"]:config[\"train_size\"]+config[\"val_size\"]]\n",
    "data = data[:config[\"train_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsa0heCPpow7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 16:37:00.086181 4646585792 toolwrapper.py:77] stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    }
   ],
   "source": [
    "EN_lang = LangEn(config)\n",
    "JP_lang = LangJa(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWurNSGQpoug"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"en_col\"]]:\n",
    "    EN_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJgN_yKjposQ"
   },
   "outputs": [],
   "source": [
    "for s in data[config[\"jp_col\"]]:\n",
    "    JP_lang.addSentence(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5Tz-dt4YJUu"
   },
   "source": [
    "## input の加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aULbo-pO6zd7"
   },
   "outputs": [],
   "source": [
    "if config[\"src\"]==\"jp\":\n",
    "    src_col=config[\"jp_col\"]\n",
    "    trg_col=config[\"en_col\"]\n",
    "    Langs={\"src\":JP_lang,\"trg\":EN_lang}\n",
    "else:\n",
    "    src_col=config[\"en_col\"]\n",
    "    trg_col=config[\"jp_col\"]\n",
    "    Langs={\"trg\":JP_lang,\"src\":EN_lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZkMItuoprY2"
   },
   "outputs": [],
   "source": [
    "input_en = data[src_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6IBzGaKvpYS"
   },
   "outputs": [],
   "source": [
    "input_source_lang=data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
    "input_target_lang=data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x,target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Wd8_Eq1BZAS"
   },
   "outputs": [],
   "source": [
    "val_source = val_data[src_col].apply(lambda x:Langs[\"src\"].word2id(x))\n",
    "val_target = val_data[trg_col].apply(lambda x:Langs[\"trg\"].word2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNv2-2QGwJOP"
   },
   "outputs": [],
   "source": [
    "input_source_padded=sequence.pad_sequences(input_source_lang,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "input_target_padded=sequence.pad_sequences(input_target_lang,maxlen=config[\"MAX_LENGTH\"]+1,padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfY3S_5HBZAb"
   },
   "outputs": [],
   "source": [
    "val_source_padded=sequence.pad_sequences(val_source,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")\n",
    "val_target_padded=sequence.pad_sequences(val_target,maxlen=config[\"MAX_LENGTH\"],padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TQF1eCts97rK",
    "outputId": "99351eab-be3d-4687-bedb-827ded64b9dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKk9M26LiLLz"
   },
   "source": [
    "## create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "h_IvBxgqiKRQ",
    "outputId": "3e02da3c-f3b7-4b7e-b1fb-4333f1c63bdc"
   },
   "outputs": [],
   "source": [
    "#en_emb = build_en_emb(config,EN_lang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "mPSbCDH-iv3T",
    "outputId": "decf2c89-be7e-4b59-ffcb-30d8b7d53420"
   },
   "outputs": [],
   "source": [
    "#ja_emb = build_jp_emb(config,JP_lang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NicIF0E2klcw"
   },
   "outputs": [],
   "source": [
    "#if config[\"src\"]==\"en\":\n",
    " #   emb={\"src_emb\":en_emb,\"trg_emb\":ja_emb}\n",
    "#else:\n",
    " #   emb={\"src_emb\":ja_emb,\"trg_emb\":en_emb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lp4HUYWjyo_3",
    "outputId": "5334a24a-de04-4134-c187-e7e5ff209480"
   },
   "outputs": [],
   "source": [
    "#print(\"enc->\",emb[\"trg_emb\"].shape)\n",
    "#print(\"dec->\",emb[\"src_emb\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FJkygex6zeD"
   },
   "outputs": [],
   "source": [
    "#trainer = Seq2Seq(config,enc_emb=emb[\"src_emb\"],dec_emb=emb[\"trg_emb\"])\n",
    "trainer = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EY739NcJ6zeF",
    "outputId": "8c57cb1d-d7ed-4dc4-8fdd-a79db8a56f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:15000 - val_size:300\n",
      "dec_inp-> torch.Size([128, 20])\n",
      "dec_inp-> torch.Size([128, 20])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-af480b7c904c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_source_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_target_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_source_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_target_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/work/jp_en_translation/models/Transformer.py\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(self, src, trg, val_src, val_trg)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mbatch_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/jp_en_translation/models/Transformer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_tensor, target_tensor)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan loss->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# loss_sum/batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.trainIters(input_source_padded,input_target_padded,val_source_padded,val_target_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5khAA1aymGoX"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_src=val_source_padded[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.translate(val_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = trainer.translate(val_src)\n",
    "Langs[\"trg\"].id2word(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S2S_attention.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
